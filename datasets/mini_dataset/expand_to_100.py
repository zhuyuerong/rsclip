#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰©å…… mini_dataset åˆ° 100 ä¸ª DIOR æ ·æœ¬

åŠŸèƒ½ï¼š
1. åˆ é™¤æ‰€æœ‰ hrsc2016 å›¾ç‰‡ï¼ˆç¼ºå°‘æ ‡æ³¨ï¼‰
2. ä» DIOR æ•°æ®é›†éšæœºé€‰æ‹© 100 ä¸ªæ ·æœ¬
3. å¤åˆ¶å›¾ç‰‡å’Œæ ‡æ³¨æ–‡ä»¶
4. æ›´æ–° samples.json
"""

import os
import shutil
import json
import random
from pathlib import Path
import xml.etree.ElementTree as ET


def delete_hrsc2016_files(mini_dataset_dir):
    """åˆ é™¤æ‰€æœ‰ hrsc2016 æ–‡ä»¶"""
    print("=" * 70)
    print("åˆ é™¤ hrsc2016 æ–‡ä»¶")
    print("=" * 70)
    
    images_dir = mini_dataset_dir / 'images'
    
    # åˆ é™¤ hrsc2016 å›¾ç‰‡
    deleted_count = 0
    for img_file in images_dir.glob('hrsc2016_*.bmp'):
        print(f"åˆ é™¤: {img_file.name}")
        img_file.unlink()
        deleted_count += 1
    
    print(f"\nâœ… åˆ é™¤äº† {deleted_count} ä¸ª hrsc2016 æ–‡ä»¶")
    return deleted_count


def get_dior_samples(dior_dir, num_samples=100):
    """ä» DIOR æ•°æ®é›†è·å–æ ·æœ¬"""
    print("\n" + "=" * 70)
    print(f"ä» DIOR æ•°æ®é›†é€‰æ‹© {num_samples} ä¸ªæ ·æœ¬")
    print("=" * 70)
    
    trainval_dir = dior_dir / 'images' / 'trainval'
    annotations_dir = dior_dir / 'annotations' / 'horizontal'
    
    # è·å–æ‰€æœ‰æœ‰æ ‡æ³¨çš„å›¾ç‰‡
    all_images = []
    for img_file in trainval_dir.glob('*.jpg'):
        img_id = img_file.stem
        xml_file = annotations_dir / f'{img_id}.xml'
        
        if xml_file.exists():
            # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„ç›®æ ‡
            try:
                tree = ET.parse(xml_file)
                root = tree.getroot()
                objects = root.findall('object')
                
                if len(objects) > 0:  # è‡³å°‘æœ‰ä¸€ä¸ªç›®æ ‡
                    all_images.append({
                        'image_file': img_file,
                        'xml_file': xml_file,
                        'image_id': img_id,
                        'num_objects': len(objects)
                    })
            except:
                continue
    
    print(f"æ‰¾åˆ° {len(all_images)} ä¸ªæœ‰æ•ˆçš„ DIOR æ ·æœ¬")
    
    # éšæœºé€‰æ‹©
    if len(all_images) >= num_samples:
        selected = random.sample(all_images, num_samples)
    else:
        print(f"âš ï¸ å¯ç”¨æ ·æœ¬ä¸è¶³ï¼Œä½¿ç”¨å…¨éƒ¨ {len(all_images)} ä¸ªæ ·æœ¬")
        selected = all_images
    
    # æŒ‰ç›®æ ‡æ•°é‡æ’åºï¼Œç¡®ä¿å¤šæ ·æ€§
    selected.sort(key=lambda x: x['num_objects'])
    
    print(f"\nâœ… é€‰æ‹©äº† {len(selected)} ä¸ªæ ·æœ¬")
    print(f"   ç›®æ ‡æ•°é‡èŒƒå›´: {selected[0]['num_objects']} - {selected[-1]['num_objects']}")
    
    return selected


def copy_samples_to_mini_dataset(selected_samples, mini_dataset_dir):
    """å¤åˆ¶æ ·æœ¬åˆ° mini_dataset"""
    print("\n" + "=" * 70)
    print("å¤åˆ¶æ ·æœ¬åˆ° mini_dataset")
    print("=" * 70)
    
    images_dir = mini_dataset_dir / 'images'
    annotations_dir = mini_dataset_dir / 'annotations'
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    images_dir.mkdir(exist_ok=True, parents=True)
    annotations_dir.mkdir(exist_ok=True, parents=True)
    
    samples_info = []
    
    for i, sample in enumerate(selected_samples, 1):
        # ç”Ÿæˆæ–°æ–‡ä»¶å
        new_image_name = f"DIOR_{sample['image_id']}.jpg"
        new_xml_name = f"DIOR_{sample['image_id']}.xml"
        
        # å¤åˆ¶å›¾ç‰‡
        dst_img = images_dir / new_image_name
        if not dst_img.exists():
            shutil.copy2(sample['image_file'], dst_img)
        
        # å¤åˆ¶æ ‡æ³¨
        dst_xml = annotations_dir / new_xml_name
        if not dst_xml.exists():
            shutil.copy2(sample['xml_file'], dst_xml)
        
        # è®°å½•ä¿¡æ¯
        samples_info.append({
            'dataset': 'DIOR',
            'image_name': new_image_name,
            'original_path': str(sample['image_file'].relative_to(sample['image_file'].parents[3]))
        })
        
        if i % 20 == 0:
            print(f"  å·²å¤åˆ¶ {i}/{len(selected_samples)} ä¸ªæ ·æœ¬")
    
    print(f"\nâœ… å¤åˆ¶å®Œæˆï¼å…± {len(samples_info)} ä¸ªæ ·æœ¬")
    
    return samples_info


def update_samples_json(samples_info, mini_dataset_dir):
    """æ›´æ–° samples.json"""
    print("\n" + "=" * 70)
    print("æ›´æ–° samples.json")
    print("=" * 70)
    
    samples_file = mini_dataset_dir / 'samples.json'
    
    # ä¿å­˜
    with open(samples_file, 'w', encoding='utf-8') as f:
        json.dump(samples_info, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… å·²ä¿å­˜ {len(samples_info)} ä¸ªæ ·æœ¬ä¿¡æ¯åˆ° samples.json")


def update_split_configs(mini_dataset_dir, num_samples):
    """æ›´æ–°åˆ†å‰²é…ç½®æ–‡ä»¶"""
    print("\n" + "=" * 70)
    print("æ›´æ–°åˆ†å‰²é…ç½®")
    print("=" * 70)
    
    # ä¸åŒçš„ seen æ¯”ä¾‹
    seen_ratios = [50, 60, 70, 80]
    
    all_configs = {}
    
    for seen_ratio in seen_ratios:
        num_seen = int(num_samples * seen_ratio / 100)
        num_unseen = num_samples - num_seen
        
        config = {
            "name": f"seen_{seen_ratio}",
            "total_samples": num_samples,
            "num_seen_classes": 10,
            "num_unseen_classes": 10,
            "train_samples": num_seen,
            "test_samples": num_unseen
        }
        
        all_configs[f"seen_{seen_ratio}"] = config
        
        # ä¿å­˜å•ç‹¬çš„é…ç½®æ–‡ä»¶
        config_file = mini_dataset_dir / f'split_config_seen_{seen_ratio}.json'
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… å·²ä¿å­˜ split_config_seen_{seen_ratio}.json")
    
    # ä¿å­˜æ‰€æœ‰é…ç½®
    all_configs_file = mini_dataset_dir / 'all_split_configs.json'
    with open(all_configs_file, 'w', encoding='utf-8') as f:
        json.dump(all_configs, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… å·²ä¿å­˜ all_split_configs.json")


def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "ğŸ¯" * 35)
    print("æ‰©å…… mini_dataset åˆ° 100 ä¸ª DIOR æ ·æœ¬")
    print("ğŸ¯" * 35 + "\n")
    
    # è®¾ç½®è·¯å¾„
    mini_dataset_dir = Path(__file__).parent
    dior_dir = mini_dataset_dir.parent / 'DIOR'
    
    print(f"Mini Dataset ç›®å½•: {mini_dataset_dir}")
    print(f"DIOR æ•°æ®é›†ç›®å½•: {dior_dir}")
    
    # è®¾ç½®éšæœºç§å­
    random.seed(42)
    
    # 1. åˆ é™¤ hrsc2016 æ–‡ä»¶
    delete_hrsc2016_files(mini_dataset_dir)
    
    # 2. è·å– DIOR æ ·æœ¬
    selected_samples = get_dior_samples(dior_dir, num_samples=100)
    
    # 3. å¤åˆ¶æ ·æœ¬
    samples_info = copy_samples_to_mini_dataset(selected_samples, mini_dataset_dir)
    
    # 4. æ›´æ–° samples.json
    update_samples_json(samples_info, mini_dataset_dir)
    
    # 5. æ›´æ–°åˆ†å‰²é…ç½®
    update_split_configs(mini_dataset_dir, len(samples_info))
    
    # 6. ç»Ÿè®¡ä¿¡æ¯
    print("\n" + "=" * 70)
    print("æœ€ç»ˆç»Ÿè®¡")
    print("=" * 70)
    
    images_count = len(list((mini_dataset_dir / 'images').glob('*.jpg')))
    annotations_count = len(list((mini_dataset_dir / 'annotations').glob('*.xml')))
    
    print(f"\nâœ… æ‰©å……å®Œæˆï¼")
    print(f"   å›¾ç‰‡æ•°é‡: {images_count}")
    print(f"   æ ‡æ³¨æ•°é‡: {annotations_count}")
    print(f"   æ ·æœ¬ä¿¡æ¯: {len(samples_info)} æ¡è®°å½•")
    
    print("\n" + "=" * 70)
    print("å®Œæˆï¼")
    print("=" * 70)


if __name__ == '__main__':
    main()

