# 坐标和性能计算验证报告

## 🎯 验证范围

1. ✅ IoU 计算的坐标格式
2. ✅ NMS 的坐标格式
3. ✅ mAP 计算的正确性
4. ✅ 坐标转换的一致性
5. ✅ 批次维度处理

---

## 1️⃣ Experiment3 坐标流程验证

### 完整坐标流程 ✅

```
模型输出（归一化 cxcywh）
    ↓
boxes = pred_boxes[i]  # (num_queries, 4) [cx, cy, w, h] 范围[0, 1]
    ↓
过滤低分数
    ↓
boxes_xyxy = box_cxcywh_to_xyxy(boxes)  # 转换为 xyxy，仍然归一化
    ↓
boxes_xyxy[:, [0, 2]] *= orig_w  # x坐标转换为像素
boxes_xyxy[:, [1, 3]] *= orig_h  # y坐标转换为像素
    ↓
用于 IoU 计算和 mAP 评估（像素坐标 xyxy）
```

### 代码验证 ✅

**evaluate.py 第 262-269 行**:
```python
# 转换边界框：cxcywh (归一化) -> xyxy (归一化)
if len(boxes) > 0:
    boxes_xyxy = box_cxcywh_to_xyxy(boxes)  # ✅ 正确
    
    # 转换为像素坐标
    orig_h, orig_w = targets[i]['orig_size']
    boxes_xyxy[:, [0, 2]] *= orig_w  # ✅ x坐标
    boxes_xyxy[:, [1, 3]] *= orig_h  # ✅ y坐标
```

**evaluate.py 第 290-294 行**:
```python
# 目标框转换
if len(target_boxes) > 0:
    target_boxes_xyxy = box_cxcywh_to_xyxy(target_boxes)  # ✅ 正确
    orig_h, orig_w = targets[i]['orig_size']
    target_boxes_xyxy[:, [0, 2]] *= orig_w  # ✅ x坐标
    target_boxes_xyxy[:, [1, 3]] *= orig_h  # ✅ y坐标
```

**结论**: ✅ **坐标转换完全正确**

---

## 2️⃣ IoU 计算验证

### Experiment2 IoU 实现

**文件**: `experiment2/stage4_supervision/box_loss.py`

**代码** (第 34-76 行):
```python
def generalized_box_iou(boxes1: torch.Tensor, boxes2: torch.Tensor) -> torch.Tensor:
    """
    输入格式: (x1, y1, x2, y2) - xyxy格式 ✅
    """
    # 1. 验证坐标有效性 ✅
    assert (boxes1[:, 2:] >= boxes1[:, :2]).all()
    assert (boxes2[:, 2:] >= boxes2[:, :2]).all()
    
    # 2. 计算面积 ✅
    area1 = (boxes1[:, 2] - boxes1[:, 0]) * (boxes1[:, 3] - boxes1[:, 1])
    area2 = (boxes2[:, 2] - boxes2[:, 0]) * (boxes2[:, 3] - boxes2[:, 1])
    
    # 3. 计算交集 ✅
    lt = torch.max(boxes1[:, :2], boxes2[:, :2])  # 左上角
    rb = torch.min(boxes1[:, 2:], boxes2[:, 2:])  # 右下角
    wh = (rb - lt).clamp(min=0)
    inter = wh[:, 0] * wh[:, 1]
    
    # 4. 计算并集 ✅
    union = area1 + area2 - inter
    
    # 5. 计算IoU ✅
    iou = inter / (union + 1e-6)  # 数值稳定性
    
    # 6. 计算最小外接矩形 ✅
    lt_enclosing = torch.min(boxes1[:, :2], boxes2[:, :2])
    rb_enclosing = torch.max(boxes1[:, 2:], boxes2[:, 2:])
    wh_enclosing = (rb_enclosing - lt_enclosing).clamp(min=0)
    area_enclosing = wh_enclosing[:, 0] * wh_enclosing[:, 1]
    
    # 7. 计算GIoU ✅
    giou = iou - (area_enclosing - union) / (area_enclosing + 1e-6)
    
    return giou
```

**验证结果**: ✅ **完全正确**

### Experiment3 IoU 实现

**文件**: `experiment3/losses/bbox_loss.py`

**同样实现** ✅ - 与Experiment2相同，完全正确

### Experiment3 mAP 中的 IoU

**文件**: `experiment3/evaluate.py`

**代码** (第 24-48 行):
```python
def compute_iou(box1, box2):
    """
    输入: [x1, y1, x2, y2] 像素坐标 ✅
    """
    # 1. 计算交集
    x1 = max(box1[0], box2[0])  # ✅
    y1 = max(box1[1], box2[1])  # ✅
    x2 = min(box1[2], box2[2])  # ✅
    y2 = min(box1[3], box2[3])  # ✅
    
    inter_area = max(0, x2 - x1) * max(0, y2 - y1)  # ✅
    
    # 2. 计算面积
    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])  # ✅
    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])  # ✅
    
    # 3. 计算并集
    union_area = box1_area + box2_area - inter_area  # ✅
    
    # 4. 计算IoU
    iou = inter_area / union_area if union_area > 0 else 0  # ✅
    
    return iou
```

**验证结果**: ✅ **完全正确**

---

## 3️⃣ NMS 验证

### Experiment2 NMS

**文件**: `experiment2/inference/post_processor.py`

**实现** (第 69-73 行):
```python
# 1. 转换为 xyxy 格式 ✅
boxes_xyxy = box_cxcywh_to_xyxy(boxes_filtered)

# 2. 使用 torchvision 官方 NMS ✅
keep_indices = nms(boxes_xyxy, scores_filtered, self.nms_threshold)
```

**配置**:
```python
nms_threshold: float = 0.7  # ✅ 合理（标准范围 0.5-0.7）
```

**验证结果**: ✅ **正确**

### Experiment3 NMS

**文件**: `experiment3/inference/inference_engine.py`

**实现** (第 117-153 行):
```python
def _nms(self, boxes, scores, threshold):
    """简单的NMS实现"""
    # 1. 计算面积 ✅
    areas = (x2 - x1) * (y2 - y1)
    
    # 2. 按分数排序 ✅
    _, order = scores.sort(descending=True)
    
    # 3. 迭代抑制 ✅
    while order.numel() > 0:
        i = order[0].item()
        keep.append(i)
        
        # 计算IoU
        xx1 = torch.max(x1[i], x1[order[1:]])  # ✅
        yy1 = torch.max(y1[i], y1[order[1:]])  # ✅
        xx2 = torch.min(x2[i], x2[order[1:]])  # ✅
        yy2 = torch.min(y2[i], y2[order[1:]])  # ✅
        
        w = torch.clamp(xx2 - xx1, min=0)  # ✅
        h = torch.clamp(yy2 - yy1, min=0)  # ✅
        inter = w * h
        
        iou = inter / (areas[i] + areas[order[1:]] - inter)  # ✅
        
        # 保留IoU小于阈值的框
        mask = iou <= threshold  # ✅
        order = order[1:][mask]
```

**配置**:
```python
nms_threshold: float = 0.5  # ✅ 合理
```

**验证结果**: ✅ **正确**

---

## 4️⃣ mAP 计算验证

### Experiment3 AP 计算

**文件**: `experiment3/evaluate.py`

**11点插值法** (第 51-73 行):
```python
def compute_ap(recalls, precisions):
    """计算Average Precision (11点插值法)"""
    ap = 0.0
    for t in np.arange(0., 1.1, 0.1):  # ✅ 11个点
        if np.sum(recalls >= t) == 0:
            p = 0
        else:
            p = np.max(precisions[recalls >= t])  # ✅ 取最大precision
        ap += p / 11.0  # ✅ 平均
    
    return ap
```

**验证**: ✅ **符合PASCAL VOC标准**

### mAP 计算流程

**文件**: `experiment3/evaluate.py` (第 76-209 行)

**流程**:
```python
1. 收集每个类别的预测和目标 ✅
   class_predictions[class_id] = [(confidence, image_id, box)]
   class_targets[class_id] = num_instances

2. 按置信度排序 ✅
   preds = sorted(preds, key=lambda x: x['confidence'], reverse=True)

3. 计算TP和FP ✅
   for each prediction:
       find best matching target (max IoU)
       if IoU >= threshold and not matched:
           tp[i] = 1
       else:
           fp[i] = 1

4. 计算累积TP和FP ✅
   tp_cumsum = np.cumsum(tp)
   fp_cumsum = np.cumsum(fp)

5. 计算Precision和Recall ✅
   precisions = tp_cumsum / (tp_cumsum + fp_cumsum + 1e-6)
   recalls = tp_cumsum / num_targets

6. 计算AP ✅
   ap = compute_ap(recalls, precisions)

7. 计算mAP ✅
   mAP = np.mean(list(aps.values()))
```

**验证结果**: ✅ **完全符合标准mAP计算流程**

---

## 5️⃣ 批次维度处理验证

### Experiment2 批次处理

**文件**: `experiment2/stage4_supervision/box_loss.py`

**损失计算** (第 127-151 行):
```python
for b in range(batch_size):  # ✅ 逐批次处理
    pred_idx, target_idx = matched_indices[b]
    
    if len(pred_idx) == 0:  # ✅ 处理空匹配
        continue
    
    # 获取匹配的边界框
    matched_pred = pred_boxes[b][pred_idx]      # ✅ 正确索引
    matched_target = target_boxes[b][target_idx]  # ✅ 正确索引
    
    # 计算损失
    l1_loss = F.l1_loss(matched_pred, matched_target, reduction='sum')
    
    # ... GIoU损失
    
    total_l1_loss += l1_loss
    num_boxes += len(pred_idx)

# 归一化 ✅
if num_boxes > 0:
    l1_loss_final = total_l1_loss / num_boxes  # ✅ 按目标数量归一化
```

**验证结果**: ✅ **正确**

**文件**: `experiment2/inference/post_processor.py`

**后处理** (第 52-91 行):
```python
for b in range(batch_size):  # ✅ 逐批次处理
    boxes_b = pred_boxes[b]  # (M, 4)  ✅
    scores_b = scores[b]      # (M,)    ✅
    
    # 阈值过滤
    keep_mask = scores_b > self.score_threshold
    boxes_filtered = boxes_b[keep_mask]
    scores_filtered = scores_b[keep_mask]
    
    if len(boxes_filtered) == 0:  # ✅ 处理空检测
        results.append({...})
        continue
    
    # 转换到xyxy格式
    boxes_xyxy = box_cxcywh_to_xyxy(boxes_filtered)  # ✅
    
    # NMS
    keep_indices = nms(boxes_xyxy, scores_filtered, self.nms_threshold)  # ✅
```

**验证结果**: ✅ **正确**

### Experiment3 批次处理

**文件**: `experiment3/evaluate.py`

**模型评估** (第 246-283 行):
```python
batch_size = pred_logits.shape[0]
for i in range(batch_size):  # ✅ 逐批次处理
    # 预测
    logits = pred_logits[i]  # (num_queries, num_classes)  ✅
    boxes = pred_boxes[i]    # (num_queries, 4)  ✅
    
    # 计算分数和标签
    scores = logits.sigmoid()  # ✅
    max_scores, labels = scores.max(dim=-1)  # ✅
    
    # 过滤低分数
    keep = max_scores > score_threshold
    boxes = boxes[keep]  # ✅
    scores_keep = max_scores[keep]  # ✅
    labels_keep = labels[keep]  # ✅
    
    # 坐标转换
    if len(boxes) > 0:
        boxes_xyxy = box_cxcywh_to_xyxy(boxes)  # ✅
        
        orig_h, orig_w = targets[i]['orig_size']  # ✅ 原始尺寸
        boxes_xyxy[:, [0, 2]] *= orig_w  # ✅
        boxes_xyxy[:, [1, 3]] *= orig_h  # ✅
```

**验证结果**: ✅ **完全正确**

**文件**: `experiment3/models/criterion.py`

**损失计算** (第 66-117 行):
```python
for layer_idx in range(num_layers):  # ✅ 逐层处理
    layer_logits = pred_logits[layer_idx]  # (B, num_queries, num_classes)  ✅
    layer_boxes = pred_boxes[layer_idx]    # (B, num_queries, 4)  ✅
    
    # 匹配
    indices = self.matcher(layer_logits, layer_boxes, targets)  # ✅
    
    # 收集匹配的预测和目标
    for i, (pred_idx, target_idx) in enumerate(indices):  # ✅ 逐批次
        if len(pred_idx) == 0:  # ✅ 处理空匹配
            continue
        
        # 预测
        pred_logits_matched.append(layer_logits[i][pred_idx])  # ✅
        pred_boxes_matched.append(layer_boxes[i][pred_idx])    # ✅
        
        # 目标
        target_labels_matched.append(targets[i]['labels'][target_idx])  # ✅
        target_boxes_matched.append(targets[i]['boxes'][target_idx])    # ✅
```

**验证结果**: ✅ **批次处理正确**

---

## 6️⃣ 潜在问题和修复

### ⚠️ 发现的问题

#### 问题1: Experiment3 evaluate.py 中的 IoU 计算

**当前实现** (第 24-48 行):
```python
def compute_iou(box1, box2):
    # 计算两个边界框的IoU
    # 输入: 1D array [x1, y1, x2, y2]
    ...
```

**问题**: 
- ⚠️ 这是逐对计算IoU（用于mAP评估）
- ✅ 实现正确，但只能计算两个框之间的IoU
- ✅ 在mAP计算中使用正确（第 146-152 行）

**与损失中IoU的区别**:
- `losses/bbox_loss.py`: 批量计算IoU矩阵 (N×M)
- `evaluate.py`: 逐对计算IoU (1×1)
- ✅ 两种实现都正确，用途不同

#### 问题2: mAP 计算中的重复匹配

**当前实现** (第 136-165 行):
```python
# 记录已匹配的目标
matched_targets = defaultdict(set)  # ✅ 正确

for pred_idx, pred in enumerate(preds):
    # ...
    if max_iou >= iou_threshold:
        if max_idx not in matched_targets[img_id]:  # ✅ 检查是否已匹配
            tp[pred_idx] = 1
            matched_targets[img_id].add(max_idx)  # ✅ 标记为已匹配
        else:
            fp[pred_idx] = 1  # ✅ 重复匹配视为FP
```

**验证结果**: ✅ **正确处理重复匹配**

#### 问题3: Experiment3 批次中的目标数量不一致

**当前处理** (第 283-298 行):
```python
all_predictions.append(predictions)  # ✅ 作为列表存储

# 目标
target_boxes = targets[i]['boxes']  # (N, 4)  ✅ 每个批次不同的N
target_labels = targets[i]['labels']  # (N,)  ✅

# 转换
if len(target_boxes) > 0:  # ✅ 处理空目标
    target_boxes_xyxy = box_cxcywh_to_xyxy(target_boxes)
    ...

all_targets.append({  # ✅ 作为列表存储
    'boxes': target_boxes_xyxy.cpu(),
    'labels': target_labels.cpu()
})
```

**验证结果**: ✅ **正确处理不同数量的目标**

---

## 📊 对比三个实验

### RemoteCLIP 使用对比

| 特性 | Experiment1 | Experiment2 | Experiment3 |
|------|-------------|-------------|-------------|
| 加载方式 | ✅ open_clip | ✅ open_clip | ✅ open_clip |
| 权重路径 | ✅ 统一 | ✅ 统一 | ✅ 统一 |
| 图像编码 | ✅ encode_image | ⚠️ 仅文本 | ✅ encode_image |
| 文本编码 | ✅ encode_text | ✅ encode_text | ✅ encode_text |
| 特征归一化 | ✅ L2 norm | ✅ L2 norm | ✅ L2 norm |
| 多层特征 | ❌ 无 | ❌ 无 | ✅ hooks提取 |
| 冻结权重 | ⚠️ eval模式 | ⚠️ eval模式 | ✅ requires_grad=False |

### 性能计算对比

| 指标 | Experiment1 | Experiment2 | Experiment3 |
|------|-------------|-------------|-------------|
| IoU计算 | ⚠️ 分散 | ✅ 正确 | ✅ 正确 |
| GIoU计算 | ❌ 无 | ✅ 正确 | ✅ 正确 |
| NMS | ⚠️ 简单 | ✅ torchvision | ✅ 自实现+官方 |
| mAP | ❌ 无 | ❌ 无 | ✅ 11点插值 |
| AP per class | ❌ 无 | ❌ 无 | ✅ 完整 |
| 评估脚本 | ❌ 无 | ❌ 无 | ✅ 完整 |

### 坐标格式对比

| 格式 | Experiment1 | Experiment2 | Experiment3 |
|------|-------------|-------------|-------------|
| 内部存储 | ⚠️ 混合 | ✅ cxcywh | ✅ cxcywh |
| IoU计算 | ⚠️ 未统一 | ✅ xyxy | ✅ xyxy |
| 评估使用 | ⚠️ 未明确 | ⚠️ 未实现 | ✅ xyxy像素 |
| 转换函数 | ⚠️ 分散 | ✅ 统一 | ✅ 统一 |
| 文档标注 | ❌ 缺少 | ⚠️ 部分 | ✅ 完整 |

---

## ✅ 验证结论

### RemoteCLIP 调用 ✅

**三个实验都正确调用了RemoteCLIP**:
1. ✅ 使用 `open_clip` 库
2. ✅ 加载正确的权重文件
3. ✅ 特征提取正确归一化
4. ✅ 默认使用 RN50 版本
5. ✅ 支持切换到 ViT-B-32 和 ViT-L-14

**Experiment3 最完善**:
- ✅ 提取多层级特征（hooks）
- ✅ 正确冻结权重
- ✅ 支持图像和文本双编码

### 性能计算 ⚠️

**Experiment3: 完全正确** ✅
- ✅ IoU 计算正确
- ✅ GIoU 计算正确
- ✅ mAP 计算符合标准（11点插值法）
- ✅ 坐标转换正确
- ✅ 批次处理正确
- ✅ 边界情况处理完善

**Experiment2: 部分正确** ⚠️
- ✅ IoU/GIoU 计算正确
- ✅ NMS 实现正确
- ✅ 坐标转换正确
- ❌ 缺少 mAP 实现
- ❌ 缺少评估脚本

**Experiment1: 需要改进** ⚠️
- ⚠️ 缺少统一的评估框架
- ⚠️ 坐标格式未统一
- ❌ 缺少标准的 mAP 计算

### 坐标处理 ✅

**Experiment3 作为标准参考**:
```python
# 1. 模型输出: cxcywh (归一化 [0, 1])
pred_boxes = model(...)  # (B, num_queries, 4)

# 2. 过滤和处理: 保持 cxcywh 归一化
keep = scores > threshold
boxes = pred_boxes[keep]

# 3. 评估时转换: cxcywh归一化 -> xyxy像素
boxes_xyxy = box_cxcywh_to_xyxy(boxes)
boxes_xyxy[:, [0, 2]] *= orig_w
boxes_xyxy[:, [1, 3]] *= orig_h

# 4. IoU计算: xyxy像素坐标
iou = compute_iou(pred_box, target_box)
```

---

## 🔧 改进建议

### 高优先级 ⚠️

1. **Experiment2 - 补充完整评估**
   ```python
   # 参考 Experiment3 实现：
   - experiment2/utils/evaluation.py
   - experiment2/evaluate.py
   - experiment2/utils/dataloader.py
   ```

2. **Experiment1 - 统一评估框架**
   ```python
   # 创建统一的评估模块：
   - experiment1/utils/evaluation.py
   - experiment1/evaluate.py
   ```

3. **全部 - 坐标格式文档**
   ```python
   # 在每个函数中明确标注：
   def function(boxes):
       """
       参数:
           boxes: (N, 4) [x1, y1, x2, y2] 像素坐标
                  或 [cx, cy, w, h] 归一化坐标 [0, 1]
       """
   ```

### 中优先级 ✅

4. **性能对比基准**
   - 在统一的mini_dataset上测试三个实验
   - 生成性能对比报告
   - 记录运行时间和内存占用

5. **添加更多评估指标**
   ```python
   # Experiment3 可以添加：
   - mAP@0.75
   - mAP@[0.5:0.95]
   - F1-score
   - 混淆矩阵
   ```

---

## 📈 性能计算正确性验证

### ✅ 验证通过的项目

1. **坐标转换** ✅
   - `box_cxcywh_to_xyxy` 实现正确
   - 归一化到像素坐标的转换正确
   - 所有索引操作正确

2. **IoU计算** ✅
   - 交集计算正确（max/min操作）
   - 并集计算正确
   - 数值稳定性处理（+1e-6）
   - GIoU额外项计算正确

3. **NMS** ✅
   - 使用 xyxy 坐标格式
   - 阈值设置合理（0.5-0.7）
   - 按分数排序
   - Top-K限制

4. **mAP计算** ✅ (Experiment3)
   - 11点插值法符合PASCAL VOC标准
   - TP/FP分配正确
   - Precision/Recall计算正确
   - 重复匹配处理正确

5. **批次处理** ✅
   - 逐批次迭代
   - 空检测处理
   - 不同目标数量处理
   - 维度索引正确

---

## 🎯 推荐使用

### 标准参考：Experiment3 ⭐⭐⭐⭐⭐

**优点**:
- ✅ RemoteCLIP 使用最完善（多层特征）
- ✅ 性能计算最完整（mAP、AP per class）
- ✅ 代码质量最高（文档、注释、测试）
- ✅ 坐标处理最规范（统一、清晰、正确）
- ✅ 批次处理最完善（边界情况处理）

**推荐用于**:
- 新项目开发参考
- 性能评估标准
- 代码规范示例

### 需要改进：Experiment2 ⭐⭐⭐

**优点**:
- ✅ IoU/GIoU 实现正确
- ✅ NMS 实现正确
- ✅ 损失函数设计合理

**缺点**:
- ❌ 缺少完整的评估系统
- ❌ 缺少数据加载器
- ❌ 不可直接训练

**改进方向**:
- 参考 Experiment3 补充评估系统
- 添加数据加载器
- 完善训练流程

### 需要统一：Experiment1 ⭐⭐⭐

**优点**:
- ✅ RemoteCLIP 调用正确
- ✅ 两阶段设计清晰
- ✅ 有数据加载器

**缺点**:
- ⚠️ 缺少统一的评估框架
- ⚠️ 坐标格式未统一
- ⚠️ 性能计算分散

**改进方向**:
- 统一坐标格式
- 添加标准评估模块
- 完善文档

---

## 📝 代码修复优先级

### P0 - 立即修复 🔴

1. **Experiment2 - 添加评估系统**
   - 创建 `experiment2/evaluate.py`（参考Experiment3）
   - 创建 `experiment2/utils/evaluation.py`
   - 创建 `experiment2/utils/dataloader.py`

### P1 - 尽快修复 🟡

2. **Experiment1 - 统一评估框架**
   - 创建 `experiment1/utils/evaluation.py`
   - 创建 `experiment1/evaluate.py`
   - 统一坐标格式

### P2 - 优化改进 🟢

3. **全部实验 - 文档完善**
   - 在所有函数中标注坐标格式
   - 添加性能对比测试
   - 创建最佳实践文档

---

## 📋 验证检查清单

### RemoteCLIP 调用 ✅
- [x] Experiment1 正确加载 RemoteCLIP
- [x] Experiment2 正确加载 RemoteCLIP
- [x] Experiment3 正确加载 RemoteCLIP
- [x] 权重文件路径正确
- [x] 特征归一化正确
- [x] 支持多个版本

### 坐标处理 ✅
- [x] Experiment2 坐标转换正确
- [x] Experiment3 坐标转换正确
- [x] IoU 计算使用正确格式
- [x] NMS 使用正确格式
- [x] 评估使用正确格式

### 性能计算 ⚠️
- [ ] Experiment1 缺少 mAP
- [ ] Experiment2 缺少 mAP
- [x] Experiment3 mAP 实现完整
- [x] Experiment3 批次处理正确
- [x] Experiment3 边界情况处理完善

---

## 🏆 总结

### 检查结果

✅ **RemoteCLIP 调用**: 三个实验都正确  
✅ **Experiment3**: 代码质量最高，推荐参考  
⚠️ **Experiment2**: 需要补充评估系统  
⚠️ **Experiment1**: 需要统一评估框架  

### 核心发现

1. ✅ **所有实验都正确使用了 RemoteCLIP RN50 版本**
2. ✅ **Experiment3 的性能计算完全正确**
3. ⚠️ **Experiment1/2 需要补充标准评估**
4. ✅ **坐标转换在已实现的部分都正确**

### 推荐行动

1. 以 **Experiment3 为标准模板**
2. 补充 Experiment1/2 的评估系统
3. 统一三个实验的坐标格式文档
4. 在 mini_dataset 上运行性能对比

---

**检查完成时间**: 2025-10-24  
**验证者**: AI Assistant  
**状态**: ✅ Experiment3 可用，⚠️ Experiment1/2 需要改进

