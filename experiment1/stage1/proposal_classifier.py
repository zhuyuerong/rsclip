#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Stage1: å€™é€‰æ¡†åˆ†ç±»æ¨¡å—
å¯¹ç”Ÿæˆçš„å€™é€‰æ¡†è¿›è¡Œåˆ†ç±»å’Œç½®ä¿¡åº¦è¯„ä¼°
"""

import torch
import numpy as np
from typing import List, Dict, Tuple, Optional
import open_clip
from PIL import Image
import os
import sys

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„ä»¥å¯¼å…¥åŸæœ‰æ¨¡å—
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from wordnet_vocabulary import WORDNET_REMOTE_SENSING_CLASSES, get_synonyms


class ProposalClassifier:
    """å€™é€‰æ¡†åˆ†ç±»å™¨"""
    
    def __init__(self, model_name: str = 'RN50', device: str = 'cuda'):
        """
        åˆå§‹åŒ–å€™é€‰æ¡†åˆ†ç±»å™¨
        
        å‚æ•°:
            model_name: RemoteCLIPæ¨¡å‹åç§°
            device: è®¡ç®—è®¾å¤‡
        """
        self.device = device if torch.cuda.is_available() else 'cpu'
        self.model_name = model_name
        self.model = None
        self.preprocess = None
        self.tokenizer = None
        self.class_list = None
        self.text_features = None
        
        # åˆå§‹åŒ–æ¨¡å‹
        self._load_model()
        self._setup_classification_vocabulary()
    
    def _load_model(self):
        """åŠ è½½RemoteCLIPæ¨¡å‹"""
        print(f"ğŸ”„ åŠ è½½RemoteCLIPæ¨¡å‹: {self.model_name}")
        
        self.model, _, self.preprocess = open_clip.create_model_and_transforms(self.model_name)
        self.tokenizer = open_clip.get_tokenizer(self.model_name)
        
        checkpoint_path = f"checkpoints/RemoteCLIP-{self.model_name}.pt"
        ckpt = torch.load(checkpoint_path, map_location="cpu")
        self.model.load_state_dict(ckpt)
        self.model = self.model.to(self.device).eval()
        
        print(f"âœ… æ¨¡å‹å·²åŠ è½½åˆ° {self.device}")
    
    def _setup_classification_vocabulary(self, custom_classes: List[str] = None):
        """
        è®¾ç½®åˆ†ç±»è¯è¡¨
        
        å‚æ•°:
            custom_classes: è‡ªå®šä¹‰ç±»åˆ«åˆ—è¡¨
        """
        if custom_classes:
            self.class_list = custom_classes
        else:
            # ä½¿ç”¨é»˜è®¤çš„é¥æ„Ÿç±»åˆ«
            self.class_list = WORDNET_REMOTE_SENSING_CLASSES.copy()
        
        print(f"ğŸ“‹ è®¾ç½®åˆ†ç±»è¯è¡¨: {len(self.class_list)} ä¸ªç±»åˆ«")
        
        # é¢„ç¼–ç æ–‡æœ¬ç‰¹å¾
        print("ğŸ”„ ç¼–ç æ–‡æœ¬ç‰¹å¾...")
        text_tokens = self.tokenizer(self.class_list)
        with torch.no_grad():
            self.text_features = self.model.encode_text(text_tokens.to(self.device))
            self.text_features /= self.text_features.norm(dim=-1, keepdim=True)
        
        print("âœ… æ–‡æœ¬ç‰¹å¾ç¼–ç å®Œæˆ")
    
    def classify_proposals(self, proposals: List[Dict]) -> List[Dict]:
        """
        å¯¹å€™é€‰æ¡†è¿›è¡Œåˆ†ç±»
        
        å‚æ•°:
            proposals: å€™é€‰æ¡†åˆ—è¡¨
        
        è¿”å›:
            åˆ†ç±»åçš„å€™é€‰æ¡†åˆ—è¡¨
        """
        print(f"\nğŸ”§ å¯¹ {len(proposals)} ä¸ªå€™é€‰æ¡†è¿›è¡Œåˆ†ç±»...")
        
        classified_proposals = []
        
        for proposal in proposals:
            if proposal.get('features') is None:
                continue
            
            # è·å–ç‰¹å¾
            features = torch.from_numpy(proposal['features']).to(self.device)
            
            # è®¡ç®—ä¸æ‰€æœ‰ç±»åˆ«çš„ç›¸ä¼¼åº¦
            with torch.no_grad():
                similarities = (features @ self.text_features.T).squeeze(0).cpu().numpy()
            
            # è·å–Top-Ké¢„æµ‹
            top_k = min(5, len(self.class_list))
            top_indices = similarities.argsort()[-top_k:][::-1]
            
            # æ„å»ºåˆ†ç±»ç»“æœ
            classification_results = []
            for idx in top_indices:
                classification_results.append({
                    'class': self.class_list[idx],
                    'confidence': float(similarities[idx]),
                    'rank': len(classification_results) + 1
                })
            
            # æ›´æ–°å€™é€‰æ¡†ä¿¡æ¯
            proposal['classification'] = classification_results
            proposal['predicted_class'] = classification_results[0]['class']
            proposal['prediction_confidence'] = classification_results[0]['confidence']
            proposal['top_k_predictions'] = classification_results
            
            classified_proposals.append(proposal)
        
        print(f"âœ… åˆ†ç±»å®Œæˆ")
        
        return classified_proposals
    
    def filter_proposals_by_confidence(self, proposals: List[Dict], 
                                     min_confidence: float = 0.1) -> List[Dict]:
        """
        æŒ‰ç½®ä¿¡åº¦è¿‡æ»¤å€™é€‰æ¡†
        
        å‚æ•°:
            proposals: å€™é€‰æ¡†åˆ—è¡¨
            min_confidence: æœ€å°ç½®ä¿¡åº¦é˜ˆå€¼
        
        è¿”å›:
            è¿‡æ»¤åçš„å€™é€‰æ¡†åˆ—è¡¨
        """
        print(f"\nğŸ”§ æŒ‰ç½®ä¿¡åº¦è¿‡æ»¤å€™é€‰æ¡† (é˜ˆå€¼: {min_confidence})...")
        
        filtered_proposals = []
        
        for proposal in proposals:
            confidence = proposal.get('prediction_confidence', 0)
            
            if confidence >= min_confidence:
                filtered_proposals.append(proposal)
        
        print(f"âœ… ç½®ä¿¡åº¦è¿‡æ»¤: {len(proposals)} -> {len(filtered_proposals)} ä¸ªå€™é€‰æ¡†")
        
        return filtered_proposals
    
    def filter_proposals_by_class(self, proposals: List[Dict], 
                                target_classes: List[str]) -> List[Dict]:
        """
        æŒ‰ç±»åˆ«è¿‡æ»¤å€™é€‰æ¡†
        
        å‚æ•°:
            proposals: å€™é€‰æ¡†åˆ—è¡¨
            target_classes: ç›®æ ‡ç±»åˆ«åˆ—è¡¨
        
        è¿”å›:
            è¿‡æ»¤åçš„å€™é€‰æ¡†åˆ—è¡¨
        """
        print(f"\nğŸ”§ æŒ‰ç±»åˆ«è¿‡æ»¤å€™é€‰æ¡† (ç›®æ ‡ç±»åˆ«: {target_classes})...")
        
        filtered_proposals = []
        
        for proposal in proposals:
            predicted_class = proposal.get('predicted_class', '')
            
            # æ£€æŸ¥æ˜¯å¦åŒ¹é…ç›®æ ‡ç±»åˆ«æˆ–å…¶åŒä¹‰è¯
            if predicted_class in target_classes:
                filtered_proposals.append(proposal)
                continue
            
            # æ£€æŸ¥åŒä¹‰è¯
            synonyms = get_synonyms(predicted_class)
            if any(syn in target_classes for syn in synonyms):
                filtered_proposals.append(proposal)
                continue
            
            # æ£€æŸ¥ç›®æ ‡ç±»åˆ«çš„åŒä¹‰è¯
            for target_class in target_classes:
                target_synonyms = get_synonyms(target_class)
                if predicted_class in target_synonyms:
                    filtered_proposals.append(proposal)
                    break
        
        print(f"âœ… ç±»åˆ«è¿‡æ»¤: {len(proposals)} -> {len(filtered_proposals)} ä¸ªå€™é€‰æ¡†")
        
        return filtered_proposals
    
    def rank_proposals_by_confidence(self, proposals: List[Dict]) -> List[Dict]:
        """
        æŒ‰ç½®ä¿¡åº¦æ’åºå€™é€‰æ¡†
        
        å‚æ•°:
            proposals: å€™é€‰æ¡†åˆ—è¡¨
        
        è¿”å›:
            æ’åºåçš„å€™é€‰æ¡†åˆ—è¡¨
        """
        print(f"\nğŸ”§ æŒ‰ç½®ä¿¡åº¦æ’åºå€™é€‰æ¡†...")
        
        sorted_proposals = sorted(
            proposals, 
            key=lambda x: x.get('prediction_confidence', 0), 
            reverse=True
        )
        
        print(f"âœ… æ’åºå®Œæˆ")
        
        return sorted_proposals
    
    def classify_proposals_pipeline(self, proposals: List[Dict],
                                  target_classes: List[str] = None,
                                  min_confidence: float = 0.1,
                                  top_k: int = 10) -> List[Dict]:
        """
        å®Œæ•´çš„å€™é€‰æ¡†åˆ†ç±»æµæ°´çº¿
        
        å‚æ•°:
            proposals: å€™é€‰æ¡†åˆ—è¡¨
            target_classes: ç›®æ ‡ç±»åˆ«åˆ—è¡¨
            min_confidence: æœ€å°ç½®ä¿¡åº¦é˜ˆå€¼
            top_k: è¿”å›å‰Kä¸ªç»“æœ
        
        è¿”å›:
            åˆ†ç±»åçš„å€™é€‰æ¡†åˆ—è¡¨
        """
        print(f"\nğŸš€ å¼€å§‹å€™é€‰æ¡†åˆ†ç±»æµæ°´çº¿...")
        
        # 1. åˆ†ç±»
        classified_proposals = self.classify_proposals(proposals)
        
        # 2. æŒ‰ç½®ä¿¡åº¦è¿‡æ»¤
        filtered_proposals = self.filter_proposals_by_confidence(
            classified_proposals, 
            min_confidence
        )
        
        # 3. æŒ‰ç±»åˆ«è¿‡æ»¤ï¼ˆå¦‚æœæŒ‡å®šäº†ç›®æ ‡ç±»åˆ«ï¼‰
        if target_classes:
            filtered_proposals = self.filter_proposals_by_class(
                filtered_proposals, 
                target_classes
            )
        
        # 4. æŒ‰ç½®ä¿¡åº¦æ’åº
        ranked_proposals = self.rank_proposals_by_confidence(filtered_proposals)
        
        # 5. è¿”å›Top-K
        final_proposals = ranked_proposals[:top_k]
        
        print(f"âœ… å€™é€‰æ¡†åˆ†ç±»æµæ°´çº¿å®Œæˆï¼Œè¿”å› {len(final_proposals)} ä¸ªå€™é€‰æ¡†")
        
        return final_proposals
    
    def get_classification_statistics(self, proposals: List[Dict]) -> Dict:
        """
        è·å–åˆ†ç±»ç»Ÿè®¡ä¿¡æ¯
        
        å‚æ•°:
            proposals: å€™é€‰æ¡†åˆ—è¡¨
        
        è¿”å›:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        if not proposals:
            return {}
        
        # ç»Ÿè®¡ç±»åˆ«åˆ†å¸ƒ
        class_counts = {}
        confidences = []
        
        for proposal in proposals:
            predicted_class = proposal.get('predicted_class', 'unknown')
            confidence = proposal.get('prediction_confidence', 0)
            
            class_counts[predicted_class] = class_counts.get(predicted_class, 0) + 1
            confidences.append(confidence)
        
        stats = {
            'total_proposals': len(proposals),
            'class_distribution': class_counts,
            'confidence_stats': {
                'mean': np.mean(confidences),
                'std': np.std(confidences),
                'min': np.min(confidences),
                'max': np.max(confidences)
            },
            'top_classes': sorted(class_counts.items(), key=lambda x: x[1], reverse=True)[:5]
        }
        
        return stats


def main():
    """æµ‹è¯•å€™é€‰æ¡†åˆ†ç±»å™¨"""
    print("=" * 70)
    print("æµ‹è¯•å€™é€‰æ¡†åˆ†ç±»å™¨")
    print("=" * 70)
    
    # åˆ›å»ºæ¨¡æ‹Ÿå€™é€‰æ¡†
    mock_proposals = [
        {
            'proposal_id': 0,
            'bbox': (100, 100, 200, 200),
            'area': 10000,
            'features': np.random.randn(1, 512)  # æ¨¡æ‹Ÿç‰¹å¾
        },
        {
            'proposal_id': 1,
            'bbox': (300, 200, 400, 300),
            'area': 10000,
            'features': np.random.randn(1, 512)
        },
        {
            'proposal_id': 2,
            'bbox': (150, 250, 250, 350),
            'area': 10000,
            'features': np.random.randn(1, 512)
        }
    ]
    
    # åˆ›å»ºå€™é€‰æ¡†åˆ†ç±»å™¨
    classifier = ProposalClassifier()
    
    # ç›®æ ‡ç±»åˆ«
    target_classes = ['airplane', 'building', 'ship']
    
    # è¿è¡Œå®Œæ•´æµæ°´çº¿
    classified_proposals = classifier.classify_proposals_pipeline(
        mock_proposals,
        target_classes=target_classes,
        min_confidence=0.05,
        top_k=5
    )
    
    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = classifier.get_classification_statistics(classified_proposals)
    print(f"\nğŸ“Š åˆ†ç±»ç»Ÿè®¡:")
    print(f"  æ€»å€™é€‰æ¡†æ•°: {stats.get('total_proposals', 0)}")
    print(f"  ç½®ä¿¡åº¦èŒƒå›´: {stats.get('confidence_stats', {}).get('min', 0):.3f} - {stats.get('confidence_stats', {}).get('max', 0):.3f}")
    print(f"  ç±»åˆ«åˆ†å¸ƒ: {stats.get('class_distribution', {})}")
    
    # æ˜¾ç¤ºæ¯ä¸ªå€™é€‰æ¡†çš„åˆ†ç±»ç»“æœ
    print(f"\nğŸ“‹ åˆ†ç±»ç»“æœ:")
    for i, proposal in enumerate(classified_proposals):
        print(f"  å€™é€‰æ¡† {i+1}:")
        print(f"    ä½ç½®: {proposal['bbox']}")
        print(f"    é¢„æµ‹ç±»åˆ«: {proposal.get('predicted_class', 'unknown')}")
        print(f"    ç½®ä¿¡åº¦: {proposal.get('prediction_confidence', 0):.3f}")
        
        # æ˜¾ç¤ºTop-3é¢„æµ‹
        top_predictions = proposal.get('top_k_predictions', [])[:3]
        print(f"    Top-3é¢„æµ‹:")
        for pred in top_predictions:
            print(f"      {pred['rank']}. {pred['class']}: {pred['confidence']:.3f}")
    
    print("\nâœ… å€™é€‰æ¡†åˆ†ç±»å™¨æµ‹è¯•å®Œæˆ!")


if __name__ == "__main__":
    main()
