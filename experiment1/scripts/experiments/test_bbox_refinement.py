#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•è¾¹ç•Œæ¡†å¾®è°ƒåŠŸèƒ½
åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿåœºæ™¯æ¥æ¼”ç¤ºæ¡†å¾®è°ƒçš„æ•ˆæœ
"""

import torch
import open_clip
from PIL import Image
import numpy as np
import cv2
from bbox_refinement import BBoxRefinement, compute_saliency_map


def test_bbox_refinement():
    """æµ‹è¯•æ¡†å¾®è°ƒåŠŸèƒ½"""
    print("=" * 70)
    print("è¾¹ç•Œæ¡†å¾®è°ƒåŠŸèƒ½æµ‹è¯•")
    print("=" * 70)
    
    # 1. åŠ è½½æ¨¡å‹
    print("\nğŸ”„ åŠ è½½RemoteCLIPæ¨¡å‹...")
    model_name = 'RN50'
    model, _, preprocess = open_clip.create_model_and_transforms(model_name)
    tokenizer = open_clip.get_tokenizer(model_name)
    
    checkpoint_path = f"checkpoints/RemoteCLIP-{model_name}.pt"
    ckpt = torch.load(checkpoint_path, map_location="cpu")
    model.load_state_dict(ckpt)
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model = model.to(device).eval()
    print(f"âœ… æ¨¡å‹å·²åŠ è½½åˆ° {device}")
    
    # 2. åŠ è½½æµ‹è¯•å›¾åƒ
    image_path = "assets/airport.jpg"
    pil_image = Image.open(image_path)
    cv_image = np.array(pil_image)
    print(f"âœ… å›¾åƒå·²åŠ è½½: {cv_image.shape}")
    
    # 3. è®¡ç®—æ˜¾è‘—æ€§å›¾
    print("\nğŸ”„ è®¡ç®—æ˜¾è‘—æ€§å›¾...")
    saliency_map = compute_saliency_map(cv_image)
    print(f"âœ… æ˜¾è‘—æ€§å›¾: {saliency_map.shape}, èŒƒå›´: {saliency_map.min()}-{saliency_map.max()}")
    
    # 4. åˆ›å»ºæ¨¡æ‹Ÿçš„æ­£è´Ÿæ ·æœ¬åŸå‹
    print("\nğŸ”„ åˆ›å»ºæ¨¡æ‹ŸåŸå‹...")
    
    # æ­£æ ·æœ¬ï¼šèˆªç«™æ¥¼åŒºåŸŸ
    positive_crops = [
        cv_image[50:100, 50:100],
        cv_image[100:150, 100:150],
    ]
    
    # è´Ÿæ ·æœ¬ï¼šè·‘é“åŒºåŸŸ
    negative_crops = [
        cv_image[0:50, 0:50],
        cv_image[150:200, 150:200],
    ]
    
    positive_features = []
    for crop in positive_crops:
        crop_pil = Image.fromarray(crop)
        crop_tensor = preprocess(crop_pil).unsqueeze(0)
        with torch.no_grad():
            feat = model.encode_image(crop_tensor.to(device))
            feat /= feat.norm(dim=-1, keepdim=True)
            positive_features.append(feat)
    
    positive_prototype = torch.cat(positive_features).mean(dim=0, keepdim=True)
    
    negative_features = []
    for crop in negative_crops:
        crop_pil = Image.fromarray(crop)
        crop_tensor = preprocess(crop_pil).unsqueeze(0)
        with torch.no_grad():
            feat = model.encode_image(crop_tensor.to(device))
            feat /= feat.norm(dim=-1, keepdim=True)
            negative_features.append(feat)
    
    negative_prototype = torch.cat(negative_features).mean(dim=0, keepdim=True)
    print("âœ… åŸå‹å·²åˆ›å»º")
    
    # 5. åˆ›å»ºå¾®è°ƒå™¨
    bbox_refiner = BBoxRefinement(model, preprocess, device)
    
    # 6. æµ‹è¯•ä¸åŒçš„å¾®è°ƒæ–¹æ³•
    test_bbox = (80, 80, 150, 150)
    print(f"\nåˆå§‹è¾¹ç•Œæ¡†: {test_bbox}")
    
    methods = ['position', 'scale', 'both', 'boundary']
    
    for method in methods:
        print(f"\n{'='*70}")
        print(f"æµ‹è¯•æ–¹æ³•: {method}")
        print(f"{'='*70}")
        
        result = bbox_refiner.refine_bbox_hybrid(
            image=cv_image,
            bbox=test_bbox,
            saliency_map=saliency_map,
            positive_prototype=positive_prototype,
            negative_prototype=negative_prototype,
            method=method
        )
        
        print(f"ç»“æœ:")
        print(f"  åˆå§‹bbox: {test_bbox}")
        print(f"  ä¼˜åŒ–bbox: {result['bbox']}")
        print(f"  æ˜¯å¦ä¼˜åŒ–: {result.get('refined', False)}")
        print(f"  å¯¹æ¯”åˆ†æ•°: {result.get('contrast_score', 0.0):.4f}")
        print(f"  æ˜¾è‘—æ€§åˆ†æ•°: {result.get('saliency_score', 0.0):.4f}")
        print(f"  ç»¼åˆåˆ†æ•°: {result.get('composite_score', 0.0):.4f}")
        
        if 'scale' in result:
            print(f"  å°ºåº¦å› å­: {result['scale']}")
        
        if 'iterations' in result:
            print(f"  è¿­ä»£æ¬¡æ•°: {result['iterations']}")
    
    print("\n" + "="*70)
    print("âœ… æ¡†å¾®è°ƒåŠŸèƒ½æµ‹è¯•å®Œæˆï¼")
    print("="*70)
    
    print("\nğŸ’¡ æ¡†å¾®è°ƒè¯´æ˜:")
    print("  - position: åŸºäºæ˜¾è‘—æ€§å³°å€¼ä¼˜åŒ–ä½ç½®")
    print("  - scale: å¤šå°ºåº¦æœç´¢æœ€ä½³å°ºå¯¸")
    print("  - both: å…ˆä¼˜åŒ–ä½ç½®ï¼Œå†ä¼˜åŒ–å°ºå¯¸ï¼ˆæ¨èï¼‰")
    print("  - boundary: é€æ­¥è°ƒæ•´å››æ¡è¾¹ç•Œ")
    print("\nç»¼åˆå¾—åˆ† = 0.7 Ã— å¯¹æ¯”åˆ†æ•° + 0.3 Ã— æ˜¾è‘—æ€§åˆ†æ•°")


if __name__ == "__main__":
    test_bbox_refinement()

