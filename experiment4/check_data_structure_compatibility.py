#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ£€æŸ¥å®éªŒ4çš„æ•°æ®ç»“æ„æ˜¯å¦ç¬¦åˆVVæœºåˆ¶çš„é¢„æœŸæ ¼å¼

æ£€æŸ¥ç‚¹ï¼š
1. æ¨¡å‹è¾“å‡ºæ ¼å¼ï¼šåº”è¯¥æ˜¯ [B, N+1, 512]ï¼ˆåŒ…å«CLS tokenï¼‰
2. CLS tokenæå–ï¼šfeatures[:, 0, :] â†’ [B, 512]
3. Patch tokensæå–ï¼šfeatures[:, 1:, :] â†’ [B, N, 512]
4. VVæœºåˆ¶æ˜¯å¦åº”ç”¨
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import torch
import torch.nn as nn

from experiment4.config import Config

# ç›´æ¥ä½¿ç”¨open_clipåŠ è½½RemoteCLIPï¼ˆä¸é€šè¿‡Surgeryï¼‰
try:
    import open_clip
except ImportError:
    print("éœ€è¦å®‰è£…open_clip")
    sys.exit(1)


def load_remoteclip_direct():
    """ç›´æ¥åŠ è½½RemoteCLIPï¼Œæ£€æŸ¥è¾“å‡ºæ ¼å¼"""
    checkpoint_path = "checkpoints/RemoteCLIP-ViT-B-32.pt"
    if not os.path.exists(checkpoint_path):
        alt_path = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 
                                 "checkpoints", "RemoteCLIP-ViT-B-32.pt")
        if os.path.exists(alt_path):
            checkpoint_path = alt_path
        else:
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°RemoteCLIPæƒé‡: {checkpoint_path}")
    
    print(f"åŠ è½½RemoteCLIPæƒé‡: {checkpoint_path}")
    
    config = Config()
    
    # åˆ›å»ºæ¨¡å‹
    model, _, preprocess = open_clip.create_model_and_transforms('ViT-B-32', device=config.device)
    
    # åŠ è½½æƒé‡
    checkpoint = torch.load(checkpoint_path, map_location=config.device)
    if 'state_dict' in checkpoint:
        model.load_state_dict(checkpoint['state_dict'])
    else:
        model.load_state_dict(checkpoint)
    
    model = model.to(config.device)
    model.eval()
    
    return model, preprocess, config


def check_model_output_format(model, config):
    """æ£€æŸ¥æ¨¡å‹è¾“å‡ºæ ¼å¼"""
    print("\n" + "="*70)
    print("æ£€æŸ¥æ¨¡å‹è¾“å‡ºæ ¼å¼")
    print("="*70)
    
    # åˆ›å»ºæµ‹è¯•è¾“å…¥
    images = torch.randn(2, 3, 224, 224).to(config.device)
    
    print(f"\nè¾“å…¥å›¾åƒå½¢çŠ¶: {images.shape}")
    
    with torch.no_grad():
        # æ–¹æ³•1ï¼šä½¿ç”¨æ ‡å‡†encode_imageï¼ˆè·å–å…¨å±€ç‰¹å¾ï¼‰
        global_features = model.encode_image(images)
        print(f"\nã€æ–¹æ³•1ã€‘model.encode_image(images):")
        print(f"  è¾“å‡ºå½¢çŠ¶: {global_features.shape}")
        print(f"  è¯´æ˜: è¿™æ˜¯CLS tokenï¼ˆå…¨å±€ç‰¹å¾ï¼‰")
        
        # æ–¹æ³•2ï¼šæ‰‹åŠ¨æå–æ‰€æœ‰tokensï¼ˆåŒ…æ‹¬CLSå’Œpatchesï¼‰
        visual = model.visual
        
        # è·å–patch embeddings
        x = visual.conv1(images)  # [B, 768, 7, 7] for ViT-B-32
        B, C, H, W = x.shape
        x = x.reshape(B, C, H * W).permute(0, 2, 1)  # [B, 49, 768]
        
        # æ·»åŠ CLS token
        class_embedding = visual.class_embedding.to(x.dtype)
        cls_tokens = class_embedding.unsqueeze(0).unsqueeze(0).expand(B, -1, -1)
        x = torch.cat([cls_tokens, x], dim=1)  # [B, 50, 768]
        
        # ä½ç½®ç¼–ç 
        pos_embed = visual.positional_embedding.to(x.dtype)
        x = x + pos_embed
        
        # Layer norm
        x = visual.ln_pre(x)
        
        # Transformer
        x = x.permute(1, 0, 2)  # [50, B, 768]
        x = visual.transformer(x)
        x = x.permute(1, 0, 2)  # [B, 50, 768]
        
        # Layer norm
        x = visual.ln_post(x)
        
        # æŠ•å½±åˆ°512ç»´ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if hasattr(visual, 'proj') and visual.proj is not None:
            B, N, D = x.shape
            x = x.reshape(B * N, D)
            x = x @ visual.proj
            x = x.reshape(B, N, 512)
        
        print(f"\nã€æ–¹æ³•2ã€‘æ‰‹åŠ¨æå–æ‰€æœ‰tokens:")
        print(f"  è¾“å‡ºå½¢çŠ¶: {x.shape}")
        print(f"  è¯´æ˜: [B, 50, 512] = CLS token + 49ä¸ªpatches")
        
        # æå–CLS token
        cls_features = x[:, 0, :]  # [B, 512]
        print(f"\nã€CLS Tokenã€‘x[:, 0, :]:")
        print(f"  å½¢çŠ¶: {cls_features.shape}")
        print(f"  ä¸å…¨å±€ç‰¹å¾æ˜¯å¦ç›¸åŒ: {torch.allclose(cls_features, global_features, atol=1e-5)}")
        
        # æå–patch tokens
        patch_features = x[:, 1:, :]  # [B, 49, 512]
        print(f"\nã€Patch Tokensã€‘x[:, 1:, :]:")
        print(f"  å½¢çŠ¶: {patch_features.shape}")
        print(f"  ç½‘æ ¼å¤§å°: {int(patch_features.shape[1] ** 0.5)}Ã—{int(patch_features.shape[1] ** 0.5)}")
        
    return x, cls_features, patch_features


def check_vv_mechanism(model):
    """æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†VVæœºåˆ¶"""
    print("\n" + "="*70)
    print("æ£€æŸ¥VVæœºåˆ¶")
    print("="*70)
    
    visual = model.visual
    
    # æ£€æŸ¥transformerå±‚
    if hasattr(visual, 'transformer') and hasattr(visual.transformer, 'resblocks'):
        print(f"\nTransformerå±‚æ•°: {len(visual.transformer.resblocks)}")
        
        # æ£€æŸ¥æœ€åå‡ å±‚çš„æ³¨æ„åŠ›æœºåˆ¶
        print(f"\næœ€å3å±‚çš„æ³¨æ„åŠ›ç±»å‹:")
        for i in range(1, min(4, len(visual.transformer.resblocks)) + 1):
            block = visual.transformer.resblocks[-i]
            if hasattr(block, 'attn'):
                attn = block.attn
                attn_type = type(attn).__name__
                print(f"  ç¬¬{len(visual.transformer.resblocks) - i + 1}å±‚: {attn_type}")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰VVæœºåˆ¶çš„ç‰¹å¾
                if hasattr(attn, 'qkv'):
                    print(f"    âœ“ æœ‰qkvæƒé‡")
                if hasattr(attn, 'scale_multiplier'):
                    print(f"    âœ“ æ£€æµ‹åˆ°VVæœºåˆ¶ï¼ˆscale_multiplierï¼‰")
            else:
                print(f"  ç¬¬{len(visual.transformer.resblocks) - i + 1}å±‚: æ— attnå±æ€§")
    else:
        print("\nâš ï¸ æ— æ³•è®¿é—®transformer resblocks")
    
    print(f"\nè¯´æ˜:")
    print(f"  æ ‡å‡†RemoteCLIPä½¿ç”¨æ ‡å‡†çš„MultiheadAttention")
    print(f"  å¦‚æœä½¿ç”¨VVæœºåˆ¶ï¼Œéœ€è¦æ›¿æ¢ä¸ºVVAttention")


def check_experiment4_usage():
    """æ£€æŸ¥å®éªŒ4ä¸­å¦‚ä½•ä½¿ç”¨æ¨¡å‹"""
    print("\n" + "="*70)
    print("æ£€æŸ¥å®éªŒ4çš„ç”¨æ³•")
    print("="*70)
    
    # æ£€æŸ¥train_seen.pyä¸­çš„ç”¨æ³•
    train_seen_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), "train_seen.py")
    
    if os.path.exists(train_seen_path):
        with open(train_seen_path, 'r') as f:
            content = f.read()
        
        # æŸ¥æ‰¾å…³é”®ç”¨æ³•
        if "get_patch_features" in content:
            print(f"\nâœ… å®éªŒ4ä½¿ç”¨äº† get_patch_features()")
            # æŸ¥æ‰¾å…·ä½“ç”¨æ³•
            import re
            matches = re.findall(r'get_patch_features\([^)]+\)', content)
            if matches:
                print(f"  ç”¨æ³•ç¤ºä¾‹: {matches[0] if len(matches) > 0 else 'N/A'}")
        
        if "encode_image" in content:
            print(f"\nâœ… å®éªŒ4ä½¿ç”¨äº† encode_image()")
        
        if "CLIPSurgeryWrapper" in content:
            print(f"\nâœ… å®éªŒ4ä½¿ç”¨äº† CLIPSurgeryWrapper")
    else:
        print(f"\nâš ï¸ æœªæ‰¾åˆ°train_seen.py")


def check_expected_vs_actual():
    """å¯¹æ¯”æœŸæœ›æ ¼å¼å’Œå®é™…æ ¼å¼"""
    print("\n" + "="*70)
    print("æœŸæœ›æ ¼å¼ vs å®é™…æ ¼å¼å¯¹æ¯”")
    print("="*70)
    
    print(f"\nã€æœŸæœ›æ ¼å¼ã€‘ï¼ˆVVæœºåˆ¶ï¼‰:")
    print(f"  model(images) â†’ [B, N+1, 512]  # CLS + N patches")
    print(f"  cls_features = features[:, 0, :]  # [B, 512]")
    print(f"  patch_features = features[:, 1:, :]  # [B, N, 512]")
    
    print(f"\nã€å®éªŒ4å½“å‰æ ¼å¼ã€‘:")
    print(f"  CLIPSurgeryWrapper.get_patch_features() â†’ [B, N, 512]  # åªæœ‰patchesï¼Œæ²¡æœ‰CLS")
    print(f"  âš ï¸ ç¼ºå°‘CLS tokençš„è¾“å‡º")
    
    print(f"\nã€é—®é¢˜ã€‘:")
    print(f"  1. å®éªŒ4çš„get_patch_features()åªè¿”å›patch tokensï¼Œä¸åŒ…å«CLS token")
    print(f"  2. éœ€è¦ä¿®æ”¹ä»¥åŒ¹é…VVæœºåˆ¶çš„æ ¼å¼ï¼š[B, N+1, 512]")
    print(f"  3. æˆ–è€…å•ç‹¬æä¾›CLS tokençš„æå–æ–¹æ³•")


def check_clip_surgery_wrapper():
    """æ£€æŸ¥CLIPSurgeryWrapperçš„å®é™…å®ç°"""
    print("\n" + "="*70)
    print("æ£€æŸ¥CLIPSurgeryWrapperå®ç°")
    print("="*70)
    
    clip_surgery_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 
                                      "models", "clip_surgery.py")
    
    if os.path.exists(clip_surgery_path):
        with open(clip_surgery_path, 'r') as f:
            content = f.read()
        
        # æŸ¥æ‰¾get_patch_features
        if 'def get_patch_features' in content:
            # æå–å‡½æ•°å®šä¹‰
            import re
            match = re.search(r'def get_patch_features.*?return.*?', content, re.DOTALL)
            if match:
                func_code = match.group(0)
                print(f"\nã€get_patch_featureså®ç°ã€‘:")
                print(f"{func_code[:500]}...")  # æ˜¾ç¤ºå‰500å­—ç¬¦
                
                if 'features[:, 1:, :]' in func_code:
                    print(f"\n  âœ“ ç¡®å®å»æ‰äº†CLS tokenï¼ˆfeatures[:, 1:, :]ï¼‰")
                elif 'features[:, 0, :]' in func_code:
                    print(f"\n  âš ï¸ åªè¿”å›äº†CLS token")
                else:
                    print(f"\n  ? éœ€è¦æ£€æŸ¥å…·ä½“å®ç°")
        
        # æŸ¥æ‰¾encode_image
        if 'def encode_image' in content:
            match = re.search(r'def encode_image.*?return.*?', content, re.DOTALL)
            if match:
                func_code = match.group(0)
                if 'features[:, 0, :]' in func_code:
                    print(f"\nã€encode_imageå®ç°ã€‘:")
                    print(f"  âœ“ è¿”å›CLS tokenï¼ˆfeatures[:, 0, :]ï¼‰")
    else:
        print(f"\nâš ï¸ æœªæ‰¾åˆ°clip_surgery.py")


def main():
    """ä¸»å‡½æ•°"""
    print("="*70)
    print("æ£€æŸ¥å®éªŒ4æ•°æ®ç»“æ„æ˜¯å¦ç¬¦åˆVVæœºåˆ¶æ ¼å¼")
    print("="*70)
    
    # 1. åŠ è½½æ¨¡å‹
    print("\nåŠ è½½RemoteCLIPæ¨¡å‹...")
    model, preprocess, config = load_remoteclip_direct()
    print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
    
    # 2. æ£€æŸ¥è¾“å‡ºæ ¼å¼
    all_features, cls_features, patch_features = check_model_output_format(model, config)
    
    # 3. æ£€æŸ¥VVæœºåˆ¶
    check_vv_mechanism(model)
    
    # 4. æ£€æŸ¥å®éªŒ4çš„ç”¨æ³•
    check_experiment4_usage()
    
    # 5. æ£€æŸ¥CLIPSurgeryWrapper
    check_clip_surgery_wrapper()
    
    # 6. å¯¹æ¯”æœŸæœ›å’Œå®é™…
    check_expected_vs_actual()
    
    # æ€»ç»“
    print("\n" + "="*70)
    print("æ€»ç»“å’Œå»ºè®®")
    print("="*70)
    
    print(f"\nâœ… å½“å‰çŠ¶æ€:")
    print(f"  â€¢ RemoteCLIPå¯ä»¥æå–å®Œæ•´ç‰¹å¾ [B, N+1, 512]ï¼ˆåŒ…å«CLS + patchesï¼‰")
    print(f"  â€¢ CLS token: features[:, 0, :] â†’ [B, 512]")
    print(f"  â€¢ Patch tokens: features[:, 1:, :] â†’ [B, N, 512]")
    
    print(f"\nâš ï¸ å®éªŒ4çš„é—®é¢˜:")
    print(f"  â€¢ CLIPSurgeryWrapper.get_patch_features()åªè¿”å›patchesï¼Œä¸åŒ…å«CLS")
    print(f"  â€¢ éœ€è¦ä¿®æ”¹ä»¥åŒ¹é…VVæœºåˆ¶çš„å®Œæ•´è¾“å‡ºæ ¼å¼")
    
    print(f"\nğŸ’¡ å»ºè®®:")
    print(f"  1. ä¿®æ”¹get_patch_features()è¿”å›å®Œæ•´ç‰¹å¾ [B, N+1, 512]")
    print(f"  2. æˆ–è€…æ·»åŠ get_all_features()è¿”å›å®Œæ•´ç‰¹å¾")
    print(f"  3. ç¡®ä¿èƒ½å¤Ÿåˆ†åˆ«æå–CLSå’Œpatch tokens")


if __name__ == "__main__":
    main()

