# -*- coding: utf-8 -*-
"""
å®éªŒ4.1ï¼šæ‰“å°patchç›¸ä¼¼åº¦grid
éªŒè¯GTåŒºåŸŸçš„ç›¸ä¼¼åº¦æ˜¯å¦çœŸçš„ä½äºèƒŒæ™¯
"""

import os
import sys
import torch
import torch.nn.functional as F
import numpy as np
from pathlib import Path

# æ·»åŠ è·¯å¾„
root_dir = Path(__file__).parent.parent.parent.parent
sys.path.append(str(root_dir))

from experiment4.config import Config
from experiment4.models.clip_surgery import CLIPSurgeryWrapper
from experiment4.data.dataset import get_dataloaders


def identify_gt_patches(gt_bbox, grid_size=7, image_size=224):
    """
    ç¡®å®šGT bboxè¦†ç›–çš„patchç´¢å¼•
    
    Args:
        gt_bbox: [x_min, y_min, x_max, y_max] å½’ä¸€åŒ–åæ ‡ (0-1)
        grid_size: patch gridå¤§å° (7 for ViT-B/32)
        image_size: å›¾åƒå°ºå¯¸ (224)
    
    Returns:
        gt_patches: set of (row, col) tuples
    """
    # è½¬æ¢ä¸ºåƒç´ åæ ‡
    x_min = int(gt_bbox[0] * image_size)
    y_min = int(gt_bbox[1] * image_size)
    x_max = int(gt_bbox[2] * image_size)
    y_max = int(gt_bbox[3] * image_size)
    
    # patchå°ºå¯¸
    patch_size = image_size / grid_size  # 32 for 224/7
    
    # ç¡®å®šè¦†ç›–çš„patch
    gt_patches = set()
    for row in range(grid_size):
        for col in range(grid_size):
            # patchçš„ä¸­å¿ƒç‚¹
            patch_x = (col + 0.5) * patch_size
            patch_y = (row + 0.5) * patch_size
            
            # åˆ¤æ–­æ˜¯å¦åœ¨GTæ¡†å†…
            if x_min <= patch_x <= x_max and y_min <= patch_y <= y_max:
                gt_patches.add((row, col))
    
    return gt_patches


def diagnose_single_sample(model, image, class_name, gt_bbox, device):
    """
    è¯Šæ–­å•ä¸ªæ ·æœ¬çš„patchç›¸ä¼¼åº¦åˆ†å¸ƒ
    """
    print("\n" + "="*70)
    print(f"æ ·æœ¬è¯Šæ–­ï¼š{class_name}")
    print("="*70)
    
    # æå–ç‰¹å¾
    image = image.unsqueeze(0).to(device)
    
    # è·å–å®Œæ•´ç‰¹å¾
    with torch.no_grad():
        image_features = model.get_all_features(image)  # [1, 50, 512]
        text_features = model.encode_text([class_name])  # [1, 512]
    
    # æå–patchç‰¹å¾ï¼ˆå»æ‰CLSï¼‰
    patch_features = image_features[:, 1:, :]  # [1, 49, 512]
    
    # L2å½’ä¸€åŒ–
    patch_norm = F.normalize(patch_features, dim=-1, p=2)
    text_norm = F.normalize(text_features, dim=-1, p=2)
    
    # è®¡ç®—ç›¸ä¼¼åº¦
    similarity = (patch_norm @ text_norm.T).squeeze()  # [49]
    similarity_np = similarity.cpu().numpy()
    
    # Reshapeåˆ°7x7 grid
    similarity_grid = similarity_np.reshape(7, 7)
    
    # ç¡®å®šGTåŒºåŸŸçš„patches
    gt_patches = identify_gt_patches(gt_bbox.cpu().numpy() if isinstance(gt_bbox, torch.Tensor) else gt_bbox, 
                                     grid_size=7)
    
    # æ‰“å°grid
    print(f"\nç›¸ä¼¼åº¦Grid (7x7):")
    print(f"GT bbox: [{gt_bbox[0]:.3f}, {gt_bbox[1]:.3f}, {gt_bbox[2]:.3f}, {gt_bbox[3]:.3f}]")
    print(f"GTè¦†ç›–çš„patches: {sorted(gt_patches)}")
    print()
    
    for i in range(7):
        for j in range(7):
            sim_val = similarity_grid[i, j]
            marker = "[GT]" if (i, j) in gt_patches else "    "
            
            # é¢œè‰²ç¼–ç ï¼ˆç”¨äºæ–‡æœ¬è¾“å‡ºï¼‰
            if sim_val > 0.20:
                color = "ğŸ”´"  # é«˜ç›¸ä¼¼åº¦
            elif sim_val > 0.18:
                color = "ğŸŸ "  # ä¸­é«˜
            elif sim_val > 0.16:
                color = "ğŸŸ¡"  # ä¸­ç­‰
            else:
                color = "ğŸ”µ"  # ä½
            
            print(f"{color}{sim_val:.4f}{marker}", end="  ")
        print()
    
    # ç»Ÿè®¡åˆ†æ
    gt_similarities = [similarity_grid[i, j] for i, j in gt_patches]
    bg_similarities = [similarity_grid[i, j] for i in range(7) for j in range(7) 
                       if (i, j) not in gt_patches]
    
    print(f"\n" + "-"*70)
    print(f"ç»Ÿè®¡åˆ†æ:")
    print(f"-"*70)
    print(f"GTåŒºåŸŸç›¸ä¼¼åº¦: {np.mean(gt_similarities):.4f} Â± {np.std(gt_similarities):.4f}")
    print(f"  æœ€å°: {np.min(gt_similarities):.4f}")
    print(f"  æœ€å¤§: {np.max(gt_similarities):.4f}")
    print(f"  ä¸­ä½: {np.median(gt_similarities):.4f}")
    
    print(f"\nèƒŒæ™¯åŒºåŸŸç›¸ä¼¼åº¦: {np.mean(bg_similarities):.4f} Â± {np.std(bg_similarities):.4f}")
    print(f"  æœ€å°: {np.min(bg_similarities):.4f}")
    print(f"  æœ€å¤§: {np.max(bg_similarities):.4f}")
    print(f"  ä¸­ä½: {np.median(bg_similarities):.4f}")
    
    print(f"\nå…¨å›¾ç›¸ä¼¼åº¦: {similarity_np.mean():.4f} Â± {similarity_np.std():.4f}")
    print(f"  èŒƒå›´: [{similarity_np.min():.4f}, {similarity_np.max():.4f}]")
    
    # å…³é”®æŒ‡æ ‡
    gt_avg = np.mean(gt_similarities)
    bg_avg = np.mean(bg_similarities)
    diff = gt_avg - bg_avg
    
    print(f"\n" + "="*70)
    print(f"å…³é”®å‘ç°:")
    print(f"="*70)
    print(f"GTåŒºåŸŸ vs èƒŒæ™¯: {gt_avg:.4f} vs {bg_avg:.4f}")
    print(f"å·®å¼‚: {diff:+.4f} ({diff/bg_avg*100:+.2f}%)")
    
    if gt_avg > bg_avg:
        print(f"âœ… GTåŒºåŸŸç›¸ä¼¼åº¦æ›´é«˜ï¼ˆæ­£å¸¸ï¼‰")
    else:
        print(f"âŒ GTåŒºåŸŸç›¸ä¼¼åº¦æ›´ä½ï¼ˆå¼‚å¸¸ï¼ï¼‰")
        print(f"   â†’ å¯èƒ½åŸå› ï¼šSurgeryå»å†—ä½™æŠ‘åˆ¶äº†ç›®æ ‡ç‰¹å¾")
    
    # ç™¾åˆ†ä½åˆ†æ
    print(f"\nç›¸ä¼¼åº¦åˆ†å¸ƒï¼ˆç™¾åˆ†ä½ï¼‰:")
    for p in [10, 25, 50, 75, 90, 95]:
        percentile_val = np.percentile(similarity_np, p)
        print(f"  {p:3d}%tile: {percentile_val:.4f}", end="")
        
        # æ£€æŸ¥GTåŒºåŸŸåœ¨å“ªä¸ªç™¾åˆ†ä½
        if p == 75:
            gt_below_75 = sum(1 for s in gt_similarities if s < percentile_val)
            print(f"  (GTä¸­æœ‰{gt_below_75}/{len(gt_similarities)}ä½äºæ­¤å€¼)", end="")
        print()
    
    return {
        'class_name': class_name,
        'gt_avg': float(gt_avg),
        'bg_avg': float(bg_avg),
        'diff': float(diff),
        'gt_similarities': [float(s) for s in gt_similarities],
        'bg_similarities': [float(s) for s in bg_similarities],
        'all_similarities': similarity_np.tolist()
    }


def main():
    """ä¸»å‡½æ•°"""
    print("="*70)
    print("å®éªŒ4.1ï¼šPatchç›¸ä¼¼åº¦Gridè¯Šæ–­")
    print("="*70)
    
    config = Config()
    device = config.device
    
    # åŠ è½½æ•°æ®
    print("\nåŠ è½½æ•°æ®...")
    train_loader, val_loader, test_loader, dataset = get_dataloaders(config)
    
    # åŠ è½½æ¨¡å‹
    print("\nåŠ è½½CLIP Surgeryæ¨¡å‹...")
    model = CLIPSurgeryWrapper(config)
    
    # è¯Šæ–­å‰3ä¸ªæ ·æœ¬
    print("\nå¼€å§‹è¯Šæ–­...")
    
    all_results = []
    sample_count = 0
    max_samples = 5
    
    for batch in val_loader:
        images = batch['image']
        class_names = batch['class_name']
        bboxes = batch['bbox']
        has_bbox = batch['has_bbox']
        
        for i in range(len(images)):
            if not has_bbox[i]:
                continue
            
            result = diagnose_single_sample(
                model,
                images[i],
                class_names[i],
                bboxes[i],
                device
            )
            all_results.append(result)
            
            sample_count += 1
            if sample_count >= max_samples:
                break
        
        if sample_count >= max_samples:
            break
    
    # æ±‡æ€»åˆ†æ
    print("\n" + "="*70)
    print("æ±‡æ€»åˆ†æ")
    print("="*70)
    
    gt_better_count = sum(1 for r in all_results if r['gt_avg'] > r['bg_avg'])
    bg_better_count = sum(1 for r in all_results if r['bg_avg'] > r['gt_avg'])
    
    print(f"\næ ·æœ¬ç»Ÿè®¡ï¼ˆå…±{len(all_results)}ä¸ªï¼‰:")
    print(f"  GTåŒºåŸŸæ›´é«˜: {gt_better_count}ä¸ª ({gt_better_count/len(all_results)*100:.1f}%)")
    print(f"  èƒŒæ™¯æ›´é«˜: {bg_better_count}ä¸ª ({bg_better_count/len(all_results)*100:.1f}%)")
    
    avg_diff = np.mean([r['diff'] for r in all_results])
    print(f"\nå¹³å‡å·®å¼‚ï¼ˆGT - èƒŒæ™¯ï¼‰: {avg_diff:+.4f}")
    
    if avg_diff < 0:
        print(f"\nâŒ ä¸¥é‡é—®é¢˜ï¼šGTåŒºåŸŸå¹³å‡ç›¸ä¼¼åº¦ä½äºèƒŒæ™¯{abs(avg_diff):.4f}")
        print(f"   â†’ è¿™è§£é‡Šäº†ä¸ºä»€ä¹ˆçƒ­å›¾é¢œè‰²åè½¬")
        print(f"   â†’ Surgeryå»å†—ä½™å¯èƒ½æŠ‘åˆ¶äº†ç›®æ ‡çš„å…¬å…±ç‰¹å¾")
    else:
        print(f"\nâœ… GTåŒºåŸŸç›¸ä¼¼åº¦æ›´é«˜ï¼ˆæ­£å¸¸ï¼‰")
    
    # ä¿å­˜ç»“æœ
    output_dir = Path("experiment4/experiments/exp4_diagnosis/outputs")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    import json
    with open(output_dir / "patch_grid_analysis.json", 'w', encoding='utf-8') as f:
        json.dump({
            'results': all_results,
            'summary': {
                'gt_better_count': gt_better_count,
                'bg_better_count': bg_better_count,
                'avg_diff': float(avg_diff),
                'conclusion': 'GTä½äºèƒŒæ™¯' if avg_diff < 0 else 'GTé«˜äºèƒŒæ™¯'
            }
        }, f, indent=2, ensure_ascii=False)
    
    print(f"\nâœ… ç»“æœå·²ä¿å­˜: {output_dir}/patch_grid_analysis.json")


if __name__ == "__main__":
    main()

