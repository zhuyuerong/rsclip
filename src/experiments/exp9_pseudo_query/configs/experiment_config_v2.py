"""
å®éªŒé…ç½®æ–‡ä»¶ v2 - ä¿®å¤æ¶ˆèä¸å¹²å‡€çš„é—®é¢˜

å…³é”®æ”¹è¿›:
1. è®­ç»ƒé¢„ç®—æ˜¾å¼åŒ– (epochs, eval_epochs, warmup)
2. æŒ‡æ ‡ç›®æ ‡/é¢„æœŸç°è±¡å†™è¿›config
3. Queryæ³¨å…¥æ–¹å¼æ‹†æˆæ­£äº¤å¼€å…³
4. ä½¿ç”¨inherit()ä¿è¯æ¶ˆèå¹²å‡€
5. å›ºå®štotal_queriesç­–ç•¥
"""

from dataclasses import dataclass, field, replace
from typing import Optional, List, Dict, Any, Tuple
from enum import Enum
import copy


# ==================== æšä¸¾ç±»å‹ (æ­£äº¤è®¾è®¡) ====================

class QueryGenType(Enum):
    """Q-Genæ¥æºç±»å‹ (C1æ¶ˆè)"""
    TEACHER = "teacher"
    HEATMAP = "heatmap"
    FUSION = "fusion"


class PoolMode(Enum):
    """ç‰¹å¾èšåˆæ–¹å¼ (C3æ¶ˆè)"""
    MEAN = "mean"
    HEATMAP_WEIGHTED = "heatmap_weighted"
    ATTN_POOL = "attn_pool"


class InitMode(Enum):
    """Queryåˆå§‹åŒ–æ¨¡å¼ - ä¸lossæ­£äº¤"""
    REPLACE = "replace"      # 100%æ›¿æ¢learnable
    CONCAT = "concat"        # æ‹¼æ¥ [pseudo, learnable]
    RATIO = "ratio"          # æŒ‰æ¯”ä¾‹è½¯æ··åˆ
    ATTENTION = "attention"  # Attentionèåˆ


class AlignLossType(Enum):
    """å¯¹é½Lossç±»å‹"""
    NONE = "none"
    L2 = "l2"
    COSINE = "cosine"
    INFONCE = "infonce"


class PriorLossType(Enum):
    """Prior Lossç±»å‹"""
    NONE = "none"
    CENTER = "center"
    ATTN_MAP = "attn_map"


class DebugMode(Enum):
    """è°ƒè¯•æ¨¡å¼ (ç”¨äºB1/B2è¯ä¼ªå®éªŒ)"""
    NONE = "none"
    RANDOM_QUERY = "random_query"      # B1: éšæœºquery
    SHUFFLE_HEATMAP = "shuffle_heatmap"  # B2: æ‰“ä¹±çƒ­å›¾


# ==================== é¢„æœŸç»“æœæ¨¡æ¿ ====================

@dataclass
class ExpectedBehavior:
    """å®éªŒé¢„æœŸç°è±¡ - ç”¨äºè‡ªåŠ¨éªŒè¯å’ŒæŠ¥å‘Š"""
    
    # æ­£å¸¸é¢„æœŸç°è±¡æè¿°
    normal_phenomena: List[str] = field(default_factory=list)
    
    # ç›®æ ‡æŒ‡æ ‡ (ç›¸å¯¹/ç»å¯¹)
    targets: Dict[str, Any] = field(default_factory=dict)
    # ä¾‹å¦‚: {"recall_0.5_at_epoch_10": (">", 0.3), "ap_small_vs_baseline": (">", 0)}
    
    # å¦‚æœæ²¡å‡ºç°é¢„æœŸç°è±¡ï¼Œå¯èƒ½çš„åŸå› 
    failure_modes: Dict[str, str] = field(default_factory=dict)
    # ä¾‹å¦‚: {"no_improvement": "æ£€æŸ¥queryæ³¨å…¥æ˜¯å¦ç”Ÿæ•ˆ"}
    
    # ç”¨äºè‡ªåŠ¨åˆ¤æ–­çš„é˜ˆå€¼
    sanity_checks: Dict[str, Tuple[str, float]] = field(default_factory=dict)
    # ä¾‹å¦‚: {"loss_epoch_1": ("<", 10.0), "recall_epoch_5": (">", 0.1)}


# ==================== è®­ç»ƒé¢„ç®—é…ç½® ====================

@dataclass
class TrainingBudget:
    """è®­ç»ƒé¢„ç®— - ç¡®ä¿å…¬å¹³å¯¹æ¯”"""
    max_epochs: int = 50
    warmup_epochs: int = 1
    
    # å›ºå®šè¯„ä¼°ç‚¹ (ç”¨äºæ”¶æ•›é€Ÿåº¦å¯¹æ¯”)
    eval_epochs: Tuple[int, ...] = (1, 5, 10, 20, 30, 50)
    
    # ä¿å­˜checkpointçš„epoch
    save_epochs: Tuple[int, ...] = (10, 20, 30, 50)
    
    # early stopping (å¯é€‰)
    patience: Optional[int] = None
    min_delta: float = 0.001


# ==================== Pseudo Queryé…ç½® (æ­£äº¤è®¾è®¡) ====================

@dataclass
class PseudoQueryConfig:
    """
    Pseudo Queryé…ç½® - æ­£äº¤è®¾è®¡
    
    ä¸‰ä¸ªç»´åº¦:
    1. Q-Gen: gen_type, num_pseudo, pool_mode, pool_window
    2. Q-Init: init_mode
    3. Q-Loss: align_loss_type, prior_loss_type
    """
    
    # === Q-Gen é…ç½® ===
    gen_type: QueryGenType = QueryGenType.HEATMAP
    num_pseudo_queries: int = 100
    pool_mode: PoolMode = PoolMode.HEATMAP_WEIGHTED
    pool_window: int = 3
    min_score_thresh: float = 0.1
    nms_radius: int = 2  # top-ké€‰ç‚¹æ—¶çš„NMSåŠå¾„
    
    # === Q-Init é…ç½® (ä¸lossæ­£äº¤) ===
    init_mode: InitMode = InitMode.CONCAT
    
    # === Q-Loss é…ç½® (ä¸initæ­£äº¤) ===
    align_loss_type: AlignLossType = AlignLossType.NONE
    align_loss_weight: float = 1.0
    
    prior_loss_type: PriorLossType = PriorLossType.NONE
    prior_loss_weight: float = 0.5
    
    # === æ€»Queryæ•°ç­–ç•¥ ===
    fixed_total_queries: bool = True  # æ˜¯å¦å›ºå®šæ€»æ•°
    total_queries: int = 300  # æ€»queryæ•° (fixed_totalæ—¶learnable = total - pseudo)
    
    # === è°ƒè¯•æ¨¡å¼ ===
    debug_mode: DebugMode = DebugMode.NONE


def inherit(base: PseudoQueryConfig, **kwargs) -> PseudoQueryConfig:
    """
    ä»baseé…ç½®ç»§æ‰¿ï¼Œåªä¿®æ”¹æŒ‡å®šå­—æ®µ
    ä¿è¯æ¶ˆèå®éªŒçš„å¹²å‡€æ€§
    """
    return replace(base, **kwargs)


# ==================== åŸºç¡€é…ç½® ====================

@dataclass
class BaseConfig:
    """åŸºç¡€é…ç½®"""
    # å®éªŒæ ‡è¯†
    exp_name: str = "unnamed"
    exp_version: str = "v1"
    
    # æ•°æ®
    dataset: str = "DIOR"
    data_root: str = "/path/to/DIOR"
    train_split: str = "train"
    val_split: str = "val"
    test_split: str = "test"
    
    # æ¨¡å‹åŸºç¡€
    backbone: str = "resnet50"
    hidden_dim: int = 256
    num_feature_levels: int = 4
    
    # è®­ç»ƒ
    batch_size: int = 2
    num_workers: int = 4
    lr: float = 1e-4
    lr_backbone: float = 1e-5
    weight_decay: float = 1e-4
    clip_max_norm: float = 0.1
    
    # è®­ç»ƒé¢„ç®—
    budget: TrainingBudget = field(default_factory=TrainingBudget)
    
    # è®¾å¤‡
    device: str = "cuda"
    seed: int = 42
    deterministic: bool = True


@dataclass
class DeformableDETRConfig(BaseConfig):
    """Deformable DETRé…ç½®"""
    # Transformer
    enc_layers: int = 6
    dec_layers: int = 6
    nheads: int = 8
    dim_feedforward: int = 1024
    dropout: float = 0.1
    
    # Query (æ€»æ•°)
    num_queries: int = 300
    
    # Loss
    aux_loss: bool = True
    with_box_refine: bool = True
    two_stage: bool = False
    
    # Loss weights
    cls_loss_coef: float = 2.0
    bbox_loss_coef: float = 5.0
    giou_loss_coef: float = 2.0
    
    # Pseudo Query
    use_pseudo_query: bool = False
    pseudo_config: Optional[PseudoQueryConfig] = None
    
    # é¢„æœŸç»“æœ
    expected: ExpectedBehavior = field(default_factory=ExpectedBehavior)


# ==================== A3 åŸºå‡†é…ç½® (æ‰€æœ‰æ¶ˆèçš„base) ====================

# å®šä¹‰A3çš„pseudo configä½œä¸ºæ¶ˆèåŸºå‡†
A3_PSEUDO_CONFIG = PseudoQueryConfig(
    # Q-Gen
    gen_type=QueryGenType.HEATMAP,
    num_pseudo_queries=100,
    pool_mode=PoolMode.HEATMAP_WEIGHTED,
    pool_window=3,
    min_score_thresh=0.1,
    nms_radius=2,
    # Q-Init
    init_mode=InitMode.CONCAT,
    # Q-Loss (é»˜è®¤ä¸åŠ )
    align_loss_type=AlignLossType.NONE,
    prior_loss_type=PriorLossType.NONE,
    # æ€»æ•°
    fixed_total_queries=True,
    total_queries=300,
    # Debug
    debug_mode=DebugMode.NONE,
)


# ==================== Phase A: MVPå®éªŒé…ç½® ====================

def create_A0_baseline() -> DeformableDETRConfig:
    """A0: æ ‡å‡†Deformable DETR baseline (æ— pseudo query)"""
    return DeformableDETRConfig(
        exp_name="A0_baseline_no_pseudo",
        use_pseudo_query=False,
        expected=ExpectedBehavior(
            normal_phenomena=[
                "è®­ç»ƒlosså¹³ç¨³ä¸‹é™",
                "decoderè¾“å‡ºçš„boxåˆ†å¸ƒé€æ¸ä»'å…¨å›¾ä¹±é£˜'åˆ°'ç›®æ ‡é™„è¿‘èšé›†'",
                "Recall@Kåœ¨å‰5-10ä¸ªepochæœ‰æ˜æ˜¾ä¸Šå‡",
            ],
            targets={
                "role": "å¯¹ç…§ç»„",
                "note": "A2/A3è‡³å°‘åœ¨æ”¶æ•›é€Ÿåº¦æˆ–small objectsä¸Šè¶…è¿‡å®ƒ",
            },
            failure_modes={
                "loss_not_decreasing": "æ£€æŸ¥box normalize/gt formatã€matcher/targetç»„è£…",
                "boxes_at_edge": "æ£€æŸ¥box encoding/decoding",
            },
            sanity_checks={
                "loss_epoch_1": ("<", 20.0),
                "recall_300_epoch_5": (">", 0.05),
            }
        )
    )


def create_A2_teacher() -> DeformableDETRConfig:
    """A2: Teacher proposals â†’ pseudo query (ç®¡çº¿è‡ªæ£€)"""
    return DeformableDETRConfig(
        exp_name="A2_teacher_proposal",
        use_pseudo_query=True,
        pseudo_config=inherit(A3_PSEUDO_CONFIG,
            gen_type=QueryGenType.TEACHER,
        ),
        expected=ExpectedBehavior(
            normal_phenomena=[
                "å‰æœŸæ”¶æ•›æ›´å¿« (æœ€é‡è¦)",
                "åŒæ ·epochä¸‹Recall@Kæ›´æ—©æŠ¬å¤´",
                "matched querieså æ¯”å‰æœŸæ›´é«˜",
            ],
            targets={
                "recall_0.5_at_epoch_10": (">", "A0"),  # ç›¸å¯¹ç›®æ ‡
                "ap_small_at_epoch_10": (">=", "A0"),
                "note": "åæœŸå¯èƒ½è¶‹åŒ,è¿™ä¸ç®—å¤±è´¥",
            },
            failure_modes={
                "no_speedup": "æ£€æŸ¥pseudo content/pos/referenceæ˜¯å¦å¯¹é½",
                "worse_than_A0": "æ£€æŸ¥teacher proposalsåæ ‡æ˜ å°„(åŸå›¾vs feature)",
                "diversity_issue": "æ£€æŸ¥æ··åˆç­–ç•¥æ˜¯å¦æŠŠlearnableå…¨æ›¿æ‰",
            },
            sanity_checks={
                "recall_300_epoch_5": (">", 0.1),
            }
        )
    )


def create_A3_heatmap() -> DeformableDETRConfig:
    """A3: vv-attention â†’ pseudo query (æ ¸å¿ƒæ–¹æ³•)"""
    return DeformableDETRConfig(
        exp_name="A3_heatmap_pseudo",
        use_pseudo_query=True,
        pseudo_config=A3_PSEUDO_CONFIG,
        expected=ExpectedBehavior(
            normal_phenomena=[
                "æ¯”A0æ›´å¿«æ”¶æ•›",
                "å¯†é›†å°ç›®æ ‡(ship/vehicle)Recallä¸Šå‡æ›´æ˜æ˜¾",
                "å¯èƒ½å¸¦æ¥FP(èƒŒæ™¯é«˜å“åº”)â†’mAPæœªå¿…ç«‹åˆ»æ¶¨,è¿™æ˜¯æ­£å¸¸çš„",
            ],
            targets={
                "vs_A0": "è‡³å°‘åœ¨AP_smallæˆ–Recall@0.5ä¹‹ä¸€æœ‰ç¨³å®šæå‡",
                "vs_A2": "å…è®¸ç•¥å¼±,ä½†ä¸èƒ½å…¨æŒ‡æ ‡æ˜æ˜¾åŠ£äºA2",
            },
            failure_modes={
                "no_improvement": "heatmapåæ ‡ç³»æ²¡å¯¹é½(patch vs åŸå›¾)",
                "same_as_random": "top-kå…¨æŒ¤åœ¨ä¸€ä¸ªè¿é€šåŸŸ(æ²¡æœ‰NMS)",
                "unstable": "pool_windowå¤ªå°(å™ªå£°)æˆ–å¤ªå¤§(åƒèƒŒæ™¯)",
            },
            sanity_checks={
                "recall_300_epoch_5": (">", 0.08),
            }
        )
    )


# ==================== Phase B: è¯ä¼ªå®éªŒé…ç½® ====================

def create_B1_random() -> DeformableDETRConfig:
    """B1: éšæœºquery (å¿…é¡»æ˜¾è‘—å·®)"""
    return DeformableDETRConfig(
        exp_name="B1_random_query",
        use_pseudo_query=True,
        pseudo_config=inherit(A3_PSEUDO_CONFIG,
            debug_mode=DebugMode.RANDOM_QUERY,
        ),
        expected=ExpectedBehavior(
            normal_phenomena=[
                "æ˜æ˜¾åŠ£äºA2/A3 (å°¤å…¶early epoch)",
                "ç”šè‡³å¯èƒ½æ¯”A0è¿˜å·®",
            ],
            targets={
                "recall_0.5": ("<", "A3"),
                "ap_small": ("<", "A3"),
                "note": "å¦‚æœB1â‰ˆA3,è¯´æ˜A3å¢ç›Šåªæ˜¯'å¤šäº†queries'è€Œéç©ºé—´è¯æ®",
            },
            failure_modes={
                "same_as_A3": "pseudoæ³¨å…¥å¯èƒ½æ²¡ç”Ÿæ•ˆ(è¢«mask/æ²¡å–‚è¿›decoder)",
            },
        )
    )


def create_B2_shuffled() -> DeformableDETRConfig:
    """B2: æ‰“ä¹±çƒ­å›¾ (å¿…é¡»æ˜æ˜¾æ‰)"""
    return DeformableDETRConfig(
        exp_name="B2_shuffled_heatmap",
        use_pseudo_query=True,
        pseudo_config=inherit(A3_PSEUDO_CONFIG,
            debug_mode=DebugMode.SHUFFLE_HEATMAP,
        ),
        expected=ExpectedBehavior(
            normal_phenomena=[
                "ç›¸å¯¹A3æœ‰æ˜¾è‘—ä¸‹é™ (early epochæ›´æ˜æ˜¾)",
            ],
            targets={
                "ap_small": ("<", "A3"),
                "recall_0.5": ("<", "A3"),
                "note": "å¦‚æœä¸ä¸‹é™,A3çš„å› æœé“¾ä¸æˆç«‹",
            },
            failure_modes={
                "no_drop": "heatmapä¿¡æ¯è¢«å¼±åŒ–(mixingæ¯”ä¾‹å¤ªå°)",
            },
        )
    )


# ==================== Phase C: æ¶ˆèå®éªŒé…ç½® ====================

def create_C1_ablations() -> Dict[str, DeformableDETRConfig]:
    """C1: Q-Genæ¥æºæ¶ˆè"""
    return {
        "teacher": DeformableDETRConfig(
            exp_name="C1_qgen_teacher",
            use_pseudo_query=True,
            pseudo_config=inherit(A3_PSEUDO_CONFIG, gen_type=QueryGenType.TEACHER),
        ),
        "heatmap": DeformableDETRConfig(
            exp_name="C1_qgen_heatmap",
            use_pseudo_query=True,
            pseudo_config=inherit(A3_PSEUDO_CONFIG, gen_type=QueryGenType.HEATMAP),
        ),
        "fusion": DeformableDETRConfig(
            exp_name="C1_qgen_fusion",
            use_pseudo_query=True,
            pseudo_config=inherit(A3_PSEUDO_CONFIG, gen_type=QueryGenType.FUSION),
        ),
    }


def create_C2_ablations() -> Dict[str, DeformableDETRConfig]:
    """
    C2: K (queryæ•°é‡) æ¶ˆè
    
    å…³é”®: å›ºå®štotal_queries=300, åªå˜pseudoæ•°é‡
    """
    K_values = [50, 100, 150, 200, 300]
    configs = {}
    
    for K in K_values:
        configs[f"K{K}"] = DeformableDETRConfig(
            exp_name=f"C2_K_{K}",
            use_pseudo_query=True,
            pseudo_config=inherit(A3_PSEUDO_CONFIG,
                num_pseudo_queries=K,
                fixed_total_queries=True,
                total_queries=300,  # å›ºå®š!
            ),
            expected=ExpectedBehavior(
                normal_phenomena=[
                    "æ€§èƒ½éšKå¢é•¿å…ˆå‡åå¹³/ä¸‹é™ (Uå‹æˆ–é¥±å’Œ)",
                ],
                targets={
                    "curve_shape": "æ‰¾åˆ°ç”œç‚¹åŒºé—´ (é€šå¸¸50~200)",
                },
                failure_modes={
                    "monotonic_increase": "å¯èƒ½åªæ˜¯æ€»querieså˜å¤š(æ£€æŸ¥æ˜¯å¦å›ºå®štotal)",
                },
            )
        )
    
    return configs


def create_C3_ablations() -> Dict[str, DeformableDETRConfig]:
    """C3: Q-Pool (èšåˆæ–¹å¼) æ¶ˆè"""
    return {
        "mean": DeformableDETRConfig(
            exp_name="C3_pool_mean",
            use_pseudo_query=True,
            pseudo_config=inherit(A3_PSEUDO_CONFIG, pool_mode=PoolMode.MEAN),
            expected=ExpectedBehavior(
                normal_phenomena=["é€šå¸¸æœ€å¼±ä½†æœ€ç¨³"],
            )
        ),
        "heatmap_weighted": DeformableDETRConfig(
            exp_name="C3_pool_weighted",
            use_pseudo_query=True,
            pseudo_config=inherit(A3_PSEUDO_CONFIG, pool_mode=PoolMode.HEATMAP_WEIGHTED),
            expected=ExpectedBehavior(
                normal_phenomena=["ä¸€èˆ¬æ˜¯æœ€ç¨³ä¸”æœ€å¼ºçš„é»˜è®¤"],
            )
        ),
        "attn_pool": DeformableDETRConfig(
            exp_name="C3_pool_attn",
            use_pseudo_query=True,
            pseudo_config=inherit(A3_PSEUDO_CONFIG, pool_mode=PoolMode.ATTN_POOL),
            expected=ExpectedBehavior(
                normal_phenomena=["å¯èƒ½æ›´å¼ºä½†æ›´å®¹æ˜“ä¸ç¨³ (æ³¢åŠ¨/å¯¹seedæ•æ„Ÿ)"],
            )
        ),
    }


def create_C4_ablations() -> Dict[str, DeformableDETRConfig]:
    """
    C4: Q-Use (ä½¿ç”¨æ–¹å¼) æ¶ˆè
    
    æ­£äº¤è®¾è®¡: init_mode å›ºå®š, åªå˜ loss
    """
    return {
        # åªæœ‰init, æ— é¢å¤–loss
        "init_only": DeformableDETRConfig(
            exp_name="C4_use_init_only",
            use_pseudo_query=True,
            pseudo_config=inherit(A3_PSEUDO_CONFIG,
                align_loss_type=AlignLossType.NONE,
                prior_loss_type=PriorLossType.NONE,
            ),
            expected=ExpectedBehavior(
                normal_phenomena=["baseline"],
            )
        ),
        # init + alignment loss
        "plus_align_l2": DeformableDETRConfig(
            exp_name="C4_use_plus_align_l2",
            use_pseudo_query=True,
            pseudo_config=inherit(A3_PSEUDO_CONFIG,
                align_loss_type=AlignLossType.L2,
                align_loss_weight=1.0,
                prior_loss_type=PriorLossType.NONE,
            ),
            expected=ExpectedBehavior(
                normal_phenomena=["å°å¹…ç¨³å®šæå‡ (å°¤å…¶early epoch/small objects)"],
            )
        ),
        # init + alignment + prior
        "plus_align_prior": DeformableDETRConfig(
            exp_name="C4_use_plus_align_prior",
            use_pseudo_query=True,
            pseudo_config=inherit(A3_PSEUDO_CONFIG,
                align_loss_type=AlignLossType.L2,
                align_loss_weight=1.0,
                prior_loss_type=PriorLossType.CENTER,
                prior_loss_weight=0.5,
            ),
            expected=ExpectedBehavior(
                normal_phenomena=[
                    "å¯èƒ½å†æ¶¨",
                    "ä¹Ÿå¯èƒ½å¼•å…¥FPæˆ–è®­ç»ƒä¸ç¨³ (è¿™éƒ½æ­£å¸¸,å…³é”®æ˜¯è§£é‡Š)",
                ],
            )
        ),
    }


# ==================== è¾…åŠ©å‡½æ•° ====================

def get_all_experiments() -> Dict[str, DeformableDETRConfig]:
    """è·å–æ‰€æœ‰å®éªŒé…ç½®"""
    experiments = {
        # Phase A
        "A0": create_A0_baseline(),
        "A2": create_A2_teacher(),
        "A3": create_A3_heatmap(),
        # Phase B
        "B1": create_B1_random(),
        "B2": create_B2_shuffled(),
    }
    
    # Phase C
    experiments.update({f"C1_{k}": v for k, v in create_C1_ablations().items()})
    experiments.update({f"C2_{k}": v for k, v in create_C2_ablations().items()})
    experiments.update({f"C3_{k}": v for k, v in create_C3_ablations().items()})
    experiments.update({f"C4_{k}": v for k, v in create_C4_ablations().items()})
    
    return experiments


def print_experiment_card(config: DeformableDETRConfig):
    """æ‰“å°å•ä¸ªå®éªŒçš„é…ç½®å¡ç‰‡"""
    print(f"\n{'='*60}")
    print(f"å®éªŒ: {config.exp_name}")
    print(f"{'='*60}")
    
    print(f"\nğŸ“Œ åŸºæœ¬é…ç½®:")
    print(f"   use_pseudo_query: {config.use_pseudo_query}")
    
    if config.pseudo_config:
        pc = config.pseudo_config
        print(f"\nğŸ“Œ Pseudo Queryé…ç½®:")
        print(f"   Q-Gen:")
        print(f"     gen_type: {pc.gen_type.value}")
        print(f"     num_pseudo: {pc.num_pseudo_queries}")
        print(f"     pool_mode: {pc.pool_mode.value}")
        print(f"   Q-Init:")
        print(f"     init_mode: {pc.init_mode.value}")
        print(f"   Q-Loss:")
        print(f"     align: {pc.align_loss_type.value} (w={pc.align_loss_weight})")
        print(f"     prior: {pc.prior_loss_type.value} (w={pc.prior_loss_weight})")
        print(f"   Queryæ€»æ•°:")
        print(f"     fixed_total: {pc.fixed_total_queries}")
        print(f"     total: {pc.total_queries}")
        if pc.debug_mode != DebugMode.NONE:
            print(f"   âš ï¸ Debug: {pc.debug_mode.value}")
    
    if config.expected.normal_phenomena:
        print(f"\nğŸ“Œ é¢„æœŸç°è±¡:")
        for p in config.expected.normal_phenomena:
            print(f"   â€¢ {p}")
    
    if config.expected.failure_modes:
        print(f"\nğŸ“Œ å¤±è´¥æ’æŸ¥:")
        for k, v in config.expected.failure_modes.items():
            print(f"   â€¢ {k}: {v}")


def print_all_experiments_summary():
    """æ‰“å°æ‰€æœ‰å®éªŒæ‘˜è¦"""
    print("="*70)
    print("Pseudo Query Experiments Summary (v2)")
    print("="*70)
    
    experiments = get_all_experiments()
    
    # Phase A
    print("\nğŸ“Œ Phase A: MVPå¯è¡Œæ€§å®éªŒ")
    for name in ["A0", "A2", "A3"]:
        cfg = experiments[name]
        pseudo = "æ— " if not cfg.use_pseudo_query else cfg.pseudo_config.gen_type.value
        print(f"   {name}: {cfg.exp_name} (pseudo={pseudo})")
    
    # Phase B
    print("\nğŸ“Œ Phase B: è¯ä¼ªå®éªŒ")
    for name in ["B1", "B2"]:
        cfg = experiments[name]
        debug = cfg.pseudo_config.debug_mode.value
        print(f"   {name}: {cfg.exp_name} (debug={debug})")
    
    # Phase C
    print("\nğŸ“Œ Phase C: æ¶ˆèå®éªŒ")
    c1_keys = [k for k in experiments if k.startswith("C1_")]
    c2_keys = [k for k in experiments if k.startswith("C2_")]
    c3_keys = [k for k in experiments if k.startswith("C3_")]
    c4_keys = [k for k in experiments if k.startswith("C4_")]
    
    print(f"   C1 Q-Gen: {len(c1_keys)} variants - {c1_keys}")
    print(f"   C2 K:     {len(c2_keys)} variants - {c2_keys}")
    print(f"   C3 Pool:  {len(c3_keys)} variants - {c3_keys}")
    print(f"   C4 Use:   {len(c4_keys)} variants - {c4_keys}")
    
    print(f"\næ€»è®¡: {len(experiments)} ä¸ªå®éªŒé…ç½®")
    print("="*70)


if __name__ == '__main__':
    print_all_experiments_summary()
    
    # æ‰“å°A3è¯¦ç»†é…ç½®ä½œä¸ºç¤ºä¾‹
    print_experiment_card(create_A3_heatmap())
