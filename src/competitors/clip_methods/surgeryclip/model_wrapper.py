# -*- coding: utf-8 -*-
"""
CLIP Surgeryæ¨¡å‹åŒ…è£…å™¨

å®ç°ç»Ÿä¸€æ¥å£ï¼Œé€‚é…é¥æ„Ÿæ•°æ®
"""
import torch
import numpy as np
from typing import List, Dict, Tuple, Optional, Union
from PIL import Image
from pathlib import Path
import sys
import os

# æ·»åŠ æœ¬åœ°è·¯å¾„ä»¥ä¼˜å…ˆä½¿ç”¨æœ¬åœ°å®ç°
local_clip_path = os.path.join(os.path.dirname(__file__))
if local_clip_path not in sys.path:
    sys.path.insert(0, local_clip_path)

from .clip_model import CLIP
from .clip_surgery_model import CLIPSurgery
from .build_model import build_model
from ..base_interface import BaseCLIPMethod

# CALæ¨¡å—å¯¼å…¥ï¼ˆå¯é€‰ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä¸å½±å“ï¼‰
try:
    from .cal_config import CALConfig, NegativeSampleGenerator
    from .cal_modules import CALFeatureSpace, CALSimilaritySpace, ExperimentTracker
    CAL_AVAILABLE = True
except ImportError:
    CAL_AVAILABLE = False
    CALConfig = None
    NegativeSampleGenerator = None
    CALFeatureSpace = None
    CALSimilaritySpace = None
    ExperimentTracker = None


class SurgeryCLIPWrapper(BaseCLIPMethod):
    """
    CLIP SurgeryåŒ…è£…å™¨ï¼Œå®ç°ç»Ÿä¸€æ¥å£
    """
    
    def __init__(self, 
                 model_name: str = "surgeryclip",           # "clip" æˆ– "surgeryclip"
                 checkpoint_path: str = None,               # æƒé‡æ–‡ä»¶è·¯å¾„
                 device: str = "cuda", 
                 
                 # ğŸ”¥ æ”¹ä¸ºå­—ç¬¦ä¸²ï¼ŒåŒ…å«ä¸åŒç­–ç•¥
                 use_surgery_single: str = "empty",   # "none", "empty", "background", "scene", "prompt_template", "all_classes"
                 use_surgery_multi: bool = True,       # ä¿æŒbool
                 
                 # ğŸ”¥ CALå®éªŒé…ç½®ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸å¯ç”¨ï¼‰
                 cal_config: Optional['CALConfig'] = None
                 ):
        """
        Args:
            model_name: æ¨¡å‹æ¶æ„
                - "clip": åŸå§‹CLIPï¼ˆæ— VVæ³¨æ„åŠ›ï¼‰
                - "surgeryclip": Surgery CLIPï¼ˆæœ‰VVæ³¨æ„åŠ›ï¼‰
            
            checkpoint_path: æƒé‡æ–‡ä»¶è·¯å¾„
                - "checkpoints/ViT-B-32.pt": OpenAI CLIPæƒé‡
                - "checkpoints/RemoteCLIP-ViT-B-32.pt": RemoteCLIPæƒé‡
                - æˆ–å…¶ä»–æƒé‡æ–‡ä»¶
            
            use_surgery_single: å•ç±»åˆ«æ—¶çš„Surgeryç­–ç•¥
                - "none": ä¸ç”¨Surgeryï¼Œç›´æ¥ä½™å¼¦ç›¸ä¼¼åº¦
                - "empty": Surgery + ç©ºå­—ç¬¦ä¸²redundantï¼ˆåŸå§‹æ–¹æ³•ï¼‰
                - "background": Surgery + æ·»åŠ backgroundç±»ï¼ˆè½¬å¤šç±»åˆ«ï¼‰
                - "scene": Surgery + é€šç”¨åœºæ™¯æè¿°
                - "prompt_template": Surgery + promptæ¨¡æ¿å·®å¼‚
                - "all_classes": Surgery + å…¶ä»–ç±»åˆ«å¹³å‡
            
            use_surgery_multi: å¤šç±»åˆ«æ—¶æ˜¯å¦ç”¨Surgeryï¼ˆä¿æŒboolï¼‰
                - True: ä½¿ç”¨Surgeryï¼ˆè‡ªåŠ¨è®¡ç®—redundantï¼‰
                - False: ç›´æ¥ä½™å¼¦ç›¸ä¼¼åº¦
        """
        super().__init__(model_name, device)
        self.checkpoint_path = checkpoint_path
        
        self.use_surgery_single = use_surgery_single
        self.use_surgery_multi = use_surgery_multi
        
        self.model = None
        self.preprocess = None
        
        # DIORæ‰€æœ‰ç±»åˆ«ï¼ˆå¿…é¡»åœ¨CALåˆå§‹åŒ–ä¹‹å‰å®šä¹‰ï¼‰
        self.all_classes = [
            'airplane', 'airport', 'baseballfield', 'basketballcourt', 'bridge',
            'chimney', 'dam', 'Expressway-Service-area', 'Expressway-toll-station',
            'golffield', 'groundtrackfield', 'harbor', 'overpass', 'ship',
            'stadium', 'storagetank', 'tenniscourt', 'trainstation', 'vehicle', 'windmill'
        ]
        
        # ğŸ”¥ CALæ¨¡å—åˆå§‹åŒ–ï¼ˆå¯æ’æ‹”ï¼‰
        self.cal_config = cal_config
        self.negative_generator = None
        self.cal_feature_space = None
        self.cal_similarity_space = None
        self.experiment_tracker = None
        
        if CAL_AVAILABLE and cal_config is not None and cal_config.enable_cal:
            self.negative_generator = NegativeSampleGenerator(cal_config, self.all_classes)
            self.cal_feature_space = CALFeatureSpace(cal_config)
            self.cal_similarity_space = CALSimilaritySpace(cal_config)
            self.experiment_tracker = ExperimentTracker()
            print(f"âœ… CALå·²å¯ç”¨: {cal_config.get_experiment_id()}")
        elif cal_config is not None and cal_config.enable_cal:
            print("âš ï¸  CALæ¨¡å—æœªæ‰¾åˆ°ï¼ŒCALåŠŸèƒ½å°†è¢«ç¦ç”¨")

    def load_model(self, checkpoint_path: Optional[str] = None):
        """åŠ è½½æ¨¡å‹"""
        if checkpoint_path is None:
            checkpoint_path = self.checkpoint_path
        
        if checkpoint_path is None:
            raise ValueError("å¿…é¡»æä¾› checkpoint_path")
        
        # ğŸ”¥ ç»Ÿä¸€ä½¿ç”¨ build_modelï¼Œæ ¹æ® model_name å†³å®šæ¶æ„
        from .build_model import build_model
        
        self.model, self.preprocess = build_model(
            model_name=self.model_name,  # "clip" æˆ– "surgeryclip"
            checkpoint_path=checkpoint_path,
            device=self.device
        )
    
    def _find_checkpoint_in_checkpoints_dir(self) -> Optional[str]:
        """åœ¨checkpointsç›®å½•ä¸­æŸ¥æ‰¾åŒ¹é…çš„æƒé‡æ–‡ä»¶"""
        import os
        # è·å–é¡¹ç›®æ ¹ç›®å½•
        current_dir = os.path.dirname(os.path.abspath(__file__))
        project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(current_dir))))
        checkpoints_dir = os.path.join(project_root, "checkpoints")
        
        if not os.path.exists(checkpoints_dir):
            return None
        
        # æ¨¡å‹åç§°åˆ°checkpointæ–‡ä»¶çš„æ˜ å°„
        model_to_checkpoint = {
            "ViT-B/32": "RemoteCLIP-ViT-B-32.pt",  # ä¼˜å…ˆä½¿ç”¨RemoteCLIPæƒé‡
            "ViT-B/16": "RemoteCLIP-ViT-B-16.pt",
            "ViT-L/14": "RemoteCLIP-ViT-L-14.pt",
            "RN50": "RemoteCLIP-RN50.pt",
            # åŸå§‹CLIPæƒé‡ä½œä¸ºå¤‡é€‰
            "CLIP-ViT-B/32": "ViT-B-32.pt",
            "CLIP-ViT-B/16": "ViT-B-16.pt", 
            "CLIP-ViT-L/14": "ViT-L-14.pt",
        }
        
        checkpoint_name = model_to_checkpoint.get(self.model_name)
        if checkpoint_name:
            checkpoint_path = os.path.join(checkpoints_dir, checkpoint_name)
            if os.path.exists(checkpoint_path):
                return checkpoint_path
        
        # å¦‚æœæ²¡æœ‰ç²¾ç¡®åŒ¹é…ï¼Œå°è¯•æŸ¥æ‰¾åŒ…å«æ¨¡å‹åç§°çš„æ–‡ä»¶
        for filename in os.listdir(checkpoints_dir):
            if filename.endswith('.pt'):
                # æ£€æŸ¥æ–‡ä»¶åæ˜¯å¦åŒ…å«æ¨¡å‹åç§°çš„å…³é”®éƒ¨åˆ†
                model_key = self.model_name.replace('/', '-').replace('ViT-', 'ViT-')
                if model_key in filename or self.model_name.replace('/', '') in filename:
                    return os.path.join(checkpoints_dir, filename)
        
        return None
    
    def encode_image(self, image: Union[torch.Tensor, Image.Image, np.ndarray]) -> torch.Tensor:
        """ç¼–ç å›¾åƒ"""
        if self.model is None:
            self.load_model()
        
        # é¢„å¤„ç†
        if isinstance(image, Image.Image):
            image_tensor = self.preprocess(image).unsqueeze(0).to(self.device)
        elif isinstance(image, np.ndarray):
            image_pil = Image.fromarray(image)
            image_tensor = self.preprocess(image_pil).unsqueeze(0).to(self.device)
        else:
            image_tensor = image.to(self.device) if not image.is_cuda else image
        
        with torch.no_grad():
            image_features = self.model.encode_image(image_tensor)
        
        return image_features
    
    def encode_text(self, text: Union[str, List[str]], use_prompt_ensemble: bool = True) -> torch.Tensor:
        """ç¼–ç æ–‡æœ¬
        
        Args:
            text: æ–‡æœ¬æˆ–æ–‡æœ¬åˆ—è¡¨
            use_prompt_ensemble: æ˜¯å¦ä½¿ç”¨prompt ensembleï¼ˆCLIP Surgeryçš„æ ‡å‡†æ–¹å¼ï¼‰
        """
        if self.model is None:
            self.load_model()
        
        if isinstance(text, str):
            text = [text]
        
        if use_prompt_ensemble:
            # ä½¿ç”¨CLIP Surgeryçš„prompt ensembleæ–¹å¼ï¼ˆæ ‡å‡†æ–¹å¼ï¼‰
            from .clip import encode_text_with_prompt_ensemble
            with torch.no_grad():
                text_features = encode_text_with_prompt_ensemble(
                    self.model, text, self.device
                )
        else:
            # ç®€å•æ–¹å¼ï¼ˆç”¨äºå…¼å®¹ï¼‰
            from .clip import tokenize
            text_tokens = tokenize(text).to(self.device)
            with torch.no_grad():
                text_features = self.model.encode_text(text_tokens)
            # å½’ä¸€åŒ–
            text_features = text_features / text_features.norm(dim=-1, keepdim=True)
        
        return text_features
    
    def compute_similarity(self, image: Union[torch.Tensor, Image.Image, np.ndarray],
                          text: Union[str, List[str]]) -> torch.Tensor:
        """è®¡ç®—ç›¸ä¼¼åº¦"""
        image_features = self.encode_image(image)
        text_features = self.encode_text(text)
        
        # å½’ä¸€åŒ–
        image_features = image_features / image_features.norm(dim=-1, keepdim=True)
        text_features = text_features / text_features.norm(dim=-1, keepdim=True)
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        similarity = (image_features @ text_features.T) * 100.0  # CLIPçš„logit_scale
        
        return similarity
    
    def generate_heatmap(self, image: Union[torch.Tensor, Image.Image, np.ndarray],
                        text: Union[str, List[str]],
                        return_features: bool = False) -> Union[np.ndarray, Tuple[np.ndarray, Dict]]:
        """ç”Ÿæˆçƒ­å›¾"""
        if self.model is None:
            self.load_model()
        
        # é¢„å¤„ç†å›¾åƒ
        if isinstance(image, Image.Image):
            image_pil = image
            image_tensor = self.preprocess(image).unsqueeze(0).to(self.device)
        elif isinstance(image, np.ndarray):
            image_pil = Image.fromarray(image)
            image_tensor = self.preprocess(image_pil).unsqueeze(0).to(self.device)
        else:
            image_tensor = image.to(self.device) if not image.is_cuda else image
            image_pil = None
        
        # è·å–å›¾åƒå°ºå¯¸
        if isinstance(image_pil, Image.Image):
            target_h, target_w = image_pil.size[1], image_pil.size[0]
        else:
            target_h, target_w = 224, 224
        
        try:
            with torch.no_grad():
                # è·å–å›¾åƒç‰¹å¾
                image_features_all = self.model.encode_image(image_tensor)
                image_features_all = image_features_all / image_features_all.norm(dim=-1, keepdim=True)
                
                # ä½¿ç”¨CLIP Surgeryçš„prompt ensembleæ–¹å¼ç¼–ç æ–‡æœ¬
                from .clip import encode_text_with_prompt_ensemble, clip_feature_surgery
                text_features = encode_text_with_prompt_ensemble(self.model, text, self.device)
                
                # ğŸ”¥ æ ¹æ®ç±»åˆ«æ•°é‡é€‰æ‹©å¯¹åº”çš„é…ç½®
                is_single_class = (len(text) == 1)
                
                # ğŸ” å…³é”®æ£€æŸ¥ç‚¹ï¼šç¡®è®¤èµ°äº†å“ªä¸ªåˆ†æ”¯
                print(f"\n{'='*60}")
                print(f"generate_heatmap è°ƒç”¨:")
                print(f"  text: {text}")
                print(f"  use_surgery_single: {self.use_surgery_single}")
                print(f"  is_single_class: {is_single_class}")
                
                if is_single_class:
                    # ============ å•ç±»åˆ«åˆ†æ”¯ ============
                    
                    if self.use_surgery_single == "none":
                        # ç­–ç•¥0: ä¸ç”¨Surgery
                        print(f"  âœ… èµ°åˆ†æ”¯: none (ç›´æ¥ä½™å¼¦)")
                        print("ğŸ” å•ç±»åˆ«: ç›´æ¥ä½™å¼¦ç›¸ä¼¼åº¦")
                        text_features = encode_text_with_prompt_ensemble(self.model, text, self.device)
                        similarity_maps = image_features_all @ text_features.t()
                    
                    elif self.use_surgery_single == "empty":
                        # ç­–ç•¥1: ç©ºå­—ç¬¦ä¸²ï¼ˆåŸå§‹ï¼‰
                        print(f"  âœ… èµ°åˆ†æ”¯: empty (ç©ºå­—ç¬¦ä¸²)")
                        print("ğŸ” å•ç±»åˆ«Surgery: ç©ºå­—ç¬¦ä¸²redundant")
                        text_features = encode_text_with_prompt_ensemble(self.model, text, self.device)
                        redundant_features = encode_text_with_prompt_ensemble(
                            self.model, [""], self.device
                        )
                        similarity_maps = clip_feature_surgery(
                            image_features_all, text_features, redundant_features
                        )
                    
                    elif self.use_surgery_single == "background":
                        # ç­–ç•¥2: æ·»åŠ backgroundç±»ï¼ˆè½¬å¤šç±»åˆ«ï¼‰
                        print(f"  âœ… èµ°åˆ†æ”¯: background (æ·»åŠ èƒŒæ™¯ç±»)")
                        print("ğŸ” å•ç±»åˆ«Surgery: æ·»åŠ backgroundç±»ï¼ˆè½¬å¤šç±»åˆ«ï¼‰")
                        extended_text = text + ["background"]
                        extended_text_features = encode_text_with_prompt_ensemble(
                            self.model, extended_text, self.device
                        )
                        similarity_maps = clip_feature_surgery(
                            image_features_all, extended_text_features, redundant_feats=None
                        )
                        # åªå–ç›®æ ‡ç±»åˆ«çš„ç›¸ä¼¼åº¦
                        similarity_maps = similarity_maps[:, :, 0:1]
                    
                    elif self.use_surgery_single == "scene":
                        # ç­–ç•¥3: é€šç”¨åœºæ™¯æè¿°
                        print(f"  âœ… èµ°åˆ†æ”¯: scene (åœºæ™¯æè¿°)")
                        print("ğŸ” å•ç±»åˆ«Surgery: é€šç”¨åœºæ™¯æè¿°")
                        text_features = encode_text_with_prompt_ensemble(self.model, text, self.device)
                        
                        scene_descriptions = [
                            "an aerial photograph",
                            "a satellite image",
                            "remote sensing imagery"
                        ]
                        scene_features = encode_text_with_prompt_ensemble(
                            self.model, scene_descriptions, self.device
                        )
                        # å–å¹³å‡ä½œä¸ºredundant
                        redundant_features = scene_features.mean(dim=0, keepdim=True)
                        
                        similarity_maps = clip_feature_surgery(
                            image_features_all, text_features, redundant_features
                        )
                    
                    elif self.use_surgery_single == "prompt_template":
                        # ç­–ç•¥4: Promptæ¨¡æ¿å·®å¼‚
                        print(f"  âœ… èµ°åˆ†æ”¯: prompt_template (æ¨¡æ¿å·®å¼‚)")
                        print("ğŸ” å•ç±»åˆ«Surgery: Promptæ¨¡æ¿å·®å¼‚")
                        
                        target_class = text[0]
                        # å®Œæ•´prompt
                        full_prompt = [f"an aerial photo of {target_class}"]
                        text_features = encode_text_with_prompt_ensemble(
                            self.model, full_prompt, self.device
                        )
                        
                        # åªæœ‰æ¨¡æ¿
                        template_prompt = ["an aerial photo of"]
                        redundant_features = encode_text_with_prompt_ensemble(
                            self.model, template_prompt, self.device
                        )
                        
                        similarity_maps = clip_feature_surgery(
                            image_features_all, text_features, redundant_features
                        )
                    
                    elif self.use_surgery_single == "all_classes":
                        # ç­–ç•¥5: å…¶ä»–ç±»åˆ«å¹³å‡
                        print(f"  âœ… èµ°åˆ†æ”¯: all_classes (å…¶ä»–ç±»åˆ«å¹³å‡)")
                        print("ğŸ” å•ç±»åˆ«Surgery: å…¶ä»–ç±»åˆ«å¹³å‡")
                        
                        target_class = text[0]
                        text_features = encode_text_with_prompt_ensemble(self.model, text, self.device)
                        
                        # å…¶ä»–ç±»åˆ«
                        other_classes = [c for c in self.all_classes if c != target_class]
                        other_features = encode_text_with_prompt_ensemble(
                            self.model, other_classes, self.device
                        )
                        # å¹³å‡ä½œä¸ºredundant
                        redundant_features = other_features.mean(dim=0, keepdim=True)
                        
                        similarity_maps = clip_feature_surgery(
                            image_features_all, text_features, redundant_features
                        )
                    
                    else:
                        raise ValueError(f"æœªçŸ¥çš„use_surgery_single: {self.use_surgery_single}")
                
                else:  # len(text) > 1
                    # ============ å¤šç±»åˆ«åˆ†æ”¯ ============
                    text_features = encode_text_with_prompt_ensemble(self.model, text, self.device)
                    
                    if self.use_surgery_multi:
                        print("ğŸ” å¤šç±»åˆ«: Surgery + è‡ªåŠ¨è®¡ç®—redundant")
                        similarity_maps = clip_feature_surgery(
                            image_features_all, text_features, redundant_feats=None
                        )
                    else:
                        print("ğŸ” å¤šç±»åˆ«: ç›´æ¥ä½™å¼¦ç›¸ä¼¼åº¦")
                        similarity_maps = image_features_all @ text_features.t()
                
                # ç»Ÿè®¡
                print(f"   ç›¸ä¼¼åº¦: min={similarity_maps.min():.6f}, max={similarity_maps.max():.6f}, std={similarity_maps.std():.6f}")
                
                # æ’é™¤class tokenï¼Œåªä¿ç•™patch tokensçš„ç›¸ä¼¼åº¦
                similarity_maps = similarity_maps[:, 1:, :]  # [batch, num_patches, num_texts]
                
                # ğŸ” å…³é”®æ£€æŸ¥ç‚¹ï¼šå½’ä¸€åŒ–å‰çš„similarity_maps
                print(f"  å½’ä¸€åŒ–å‰ similarity_maps: min={similarity_maps.min():.6f}, max={similarity_maps.max():.6f}, std={similarity_maps.std():.6f}")
                
                # ğŸ”¥ CALæ¨¡å—ï¼šç›¸ä¼¼åº¦ç©ºé—´æ“ä½œï¼ˆå¯æ’æ‹”ï¼‰
                if (self.cal_config is not None and 
                    self.cal_config.enable_cal and 
                    self.cal_config.cal_space in ['similarity', 'both'] and
                    self.cal_similarity_space is not None):
                    
                    print(f"\n{'='*60}")
                    print(f"ğŸ”¥ CALç›¸ä¼¼åº¦ç©ºé—´æ“ä½œ")
                    print(f"  å®éªŒID: {self.cal_config.get_experiment_id()}")
                    print(f"  è´Ÿæ ·æœ¬æ¨¡å¼: {self.cal_config.negative_mode}")
                    print(f"  åŠ æƒç³»æ•°: alpha={self.cal_config.alpha}")
                    
                    # Q1: ç”Ÿæˆè´Ÿæ ·æœ¬
                    negative_texts = self.negative_generator.generate(text)
                    print(f"  è´Ÿæ ·æœ¬: {negative_texts}")
                    
                    # ç¼–ç è´Ÿæ ·æœ¬
                    negative_features = encode_text_with_prompt_ensemble(
                        self.model, negative_texts, self.device
                    )
                    
                    # åº”ç”¨CALç›¸ä¼¼åº¦ç©ºé—´æ“ä½œ
                    image_features_patches = image_features_all[:, 1:, :]
                    similarity_maps = self.cal_similarity_space.apply(
                        similarity_maps, image_features_patches, negative_features
                    )
                    
                    print(f"{'='*60}\n")
                
                # ç”Ÿæˆçƒ­å›¾
                from .clip import get_similarity_map
                heatmap_tensor = get_similarity_map(similarity_maps, (target_h, target_w))
                heatmap = heatmap_tensor[0, :, :, 0].detach().cpu().numpy()
                
                # ğŸ” å…³é”®æ£€æŸ¥ç‚¹ï¼šå½’ä¸€åŒ–åçš„heatmap
                print(f"  å½’ä¸€åŒ–å heatmap: min={heatmap.min():.6f}, max={heatmap.max():.6f}, std={heatmap.std():.6f}")
                print(f"{'='*60}\n")
                
                print(f"ğŸ” çƒ­å›¾å€¼åŸŸ: min={heatmap.min():.4f}, max={heatmap.max():.4f}, std={heatmap.std():.4f}")
                
                if np.isnan(heatmap).any() or np.isinf(heatmap).any():
                    heatmap = np.nan_to_num(heatmap, nan=0.0, posinf=1.0, neginf=0.0)
                
                heatmap = np.clip(heatmap, 0.0, 1.0)
                
                if return_features:
                    image_features_patches = image_features_all[:, 1:, :]
                    return heatmap, {
                        'image_features_all': image_features_all,
                        'image_features_patches': image_features_patches,
                        'text_features': text_features,
                        'similarity_maps': similarity_maps
                    }
                return heatmap

        except Exception as e:
            print(f"âš ï¸  çƒ­å›¾ç”Ÿæˆå¤±è´¥: {e}")
            print("ä½¿ç”¨åŸºç¡€å®ç°...")
            # å›é€€åˆ°å…¨å±€ç‰¹å¾
            image_features = self.model.encode_image(image_tensor)
            image_features = image_features / image_features.norm(dim=-1, keepdim=True)
            
            # ä½¿ç”¨ç®€å•æ–‡æœ¬ç¼–ç 
            from .clip import tokenize
            if isinstance(text, str):
                text = [text]
            text_tokens = tokenize(text).to(self.device)
            with torch.no_grad():
                text_features = self.model.encode_text(text_tokens)
            text_features = text_features / text_features.norm(dim=-1, keepdim=True)
            
            if len(text) == 1:
                similarity_val = (image_features @ text_features.t()).item()
                # åˆ›å»ºå‡åŒ€çƒ­å›¾
                if isinstance(image_pil, Image.Image):
                    h, w = image_pil.size[1], image_pil.size[0]
                else:
                    h, w = 224, 224
                heatmap = np.full((h, w), similarity_val, dtype=np.float32)
            else:
                # å¤šæ–‡æœ¬ï¼šä½¿ç”¨ç¬¬ä¸€ä¸ªæ–‡æœ¬
                similarity_val = (image_features @ text_features[0:1].t()).item()
                if isinstance(image_pil, Image.Image):
                    h, w = image_pil.size[1], image_pil.size[0]
                else:
                    h, w = 224, 224
                heatmap = np.full((h, w), similarity_val, dtype=np.float32)
            
            if return_features:
                return heatmap, {
                    'image_features': image_features,
                    'text_features': text_features
                }
            return heatmap

                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  