# Experiment3: OVA-DETR with RemoteCLIP

åŸºäºRemoteCLIPçš„å¼€æ”¾è¯æ±‡ç›®æ ‡æ£€æµ‹ç³»ç»Ÿï¼Œé›†æˆäº†OVA-DETRçš„å…ˆè¿›æ£€æµ‹æ–¹æ³•ã€‚

## ğŸ¯ é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®åœ¨RemoteCLIPçš„åŸºç¡€ä¸Šæ·»åŠ äº†ç›®æ ‡æ£€æµ‹åŠŸèƒ½ï¼Œå®ç°äº†**å¼€æ”¾è¯æ±‡çš„é¥æ„Ÿå›¾åƒç›®æ ‡æ£€æµ‹**ã€‚

### æ ¸å¿ƒç‰¹æ€§

1. **RemoteCLIPéª¨å¹²ç½‘ç»œ**ï¼šä¿ç•™é¢„è®­ç»ƒçš„å›¾åƒ-æ–‡æœ¬å¯¹é½èƒ½åŠ›
2. **OVA-DETRæ¶æ„**ï¼šå…ˆè¿›çš„å¼€æ”¾è¯æ±‡æ£€æµ‹æ–¹æ³•
3. **å¤šå±‚çº§æ–‡æœ¬-è§†è§‰èåˆ**ï¼šå……åˆ†åˆ©ç”¨æ–‡æœ¬è¯­ä¹‰ä¿¡æ¯
4. **ç«¯åˆ°ç«¯è®­ç»ƒ**ï¼šæ”¯æŒå®Œæ•´çš„è®­ç»ƒå’Œæ¨ç†æµç¨‹

## ğŸ“‚ é¡¹ç›®ç»“æ„

```
experiment3/
â”œâ”€â”€ backbone/              # RemoteCLIPéª¨å¹²ç½‘ç»œ
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ remoteclip_backbone.py
â”œâ”€â”€ encoder/               # ç¼–ç å™¨æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ fpn.py            # ç‰¹å¾é‡‘å­—å¡”ç½‘ç»œ
â”‚   â”œâ”€â”€ hybrid_encoder.py # æ··åˆç¼–ç å™¨
â”‚   â””â”€â”€ text_vision_fusion.py  # æ–‡æœ¬-è§†è§‰èåˆ
â”œâ”€â”€ decoder/               # è§£ç å™¨æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ transformer_decoder.py  # Transformerè§£ç å™¨
â”‚   â””â”€â”€ query_generator.py      # æŸ¥è¯¢ç”Ÿæˆå™¨
â”œâ”€â”€ head/                  # æ£€æµ‹å¤´
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ classification_head.py  # å¯¹æ¯”å­¦ä¹ åˆ†ç±»å¤´
â”‚   â””â”€â”€ regression_head.py      # è¾¹ç•Œæ¡†å›å½’å¤´
â”œâ”€â”€ losses/                # æŸå¤±å‡½æ•°
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ varifocal_loss.py      # å˜ç„¦æŸå¤±
â”‚   â”œâ”€â”€ bbox_loss.py           # è¾¹ç•Œæ¡†æŸå¤±
â”‚   â””â”€â”€ matcher.py             # åŒˆç‰™åˆ©åŒ¹é…å™¨
â”œâ”€â”€ models/                # å®Œæ•´æ¨¡å‹
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ ova_detr.py           # OVA-DETRæ¨¡å‹
â”‚   â””â”€â”€ criterion.py          # æŸå¤±è®¡ç®—
â”œâ”€â”€ utils/                 # å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_loader.py        # DIORæ•°æ®åŠ è½½å™¨
â”‚   â””â”€â”€ transforms.py         # æ•°æ®è½¬æ¢
â”œâ”€â”€ inference/             # æ¨ç†å¼•æ“
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ inference_engine.py
â”œâ”€â”€ config/                # é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ default_config.py
â”œâ”€â”€ train.py              # è®­ç»ƒè„šæœ¬
â”œâ”€â”€ evaluate.py           # è¯„ä¼°è„šæœ¬
â””â”€â”€ README.md            # æœ¬æ–‡æ¡£
```

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### æ•´ä½“æ¶æ„

```
è¾“å…¥å›¾åƒ (800x800)
    â†“
RemoteCLIPéª¨å¹²ç½‘ç»œ (å†»ç»“)
    â†“
FPNç‰¹å¾é‡‘å­—å¡”
    â†“
æ··åˆç¼–ç å™¨ (CNN + Transformer)
    â†“
æ–‡æœ¬-è§†è§‰èåˆ
    â†“
Transformerè§£ç å™¨ (6å±‚)
    â†“
æ£€æµ‹å¤´ (åˆ†ç±» + å›å½’)
    â†“
è¾“å‡ºï¼šè¾¹ç•Œæ¡† + ç±»åˆ«
```

### å…³é”®ç»„ä»¶

1. **RemoteCLIP Backbone**
   - æ¨¡å‹ï¼šRN50 / ViT-B-32 / ViT-L-14
   - åŠŸèƒ½ï¼šå›¾åƒç‰¹å¾æå– + æ–‡æœ¬ç‰¹å¾æå–
   - çŠ¶æ€ï¼šå†»ç»“æƒé‡ï¼ˆä¿ç•™é¢„è®­ç»ƒèƒ½åŠ›ï¼‰

2. **FPNï¼ˆç‰¹å¾é‡‘å­—å¡”ç½‘ç»œï¼‰**
   - è¾“å…¥ï¼šå¤šå±‚çº§ç‰¹å¾ (layer2, layer3, layer4)
   - è¾“å‡ºï¼š4å±‚ç‰¹å¾é‡‘å­—å¡”
   - ç»´åº¦ï¼šç»Ÿä¸€åˆ°256ç»´

3. **æ··åˆç¼–ç å™¨**
   - ä½ç½®ç¼–ç ï¼šæ­£å¼¦ä½ç½®ç¼–ç 
   - Transformerå±‚ï¼š6å±‚
   - åŠŸèƒ½ï¼šå…¨å±€ç‰¹å¾å»ºæ¨¡

4. **æ–‡æœ¬-è§†è§‰èåˆ**
   - è§†è§‰å¢å¼ºæ–‡æœ¬ï¼ˆVATï¼‰ï¼šä½¿ç”¨è§†è§‰ç‰¹å¾å¢å¼ºæ–‡æœ¬è¯­ä¹‰
   - æ–‡æœ¬å¼•å¯¼è§†è§‰ï¼šä½¿ç”¨æ–‡æœ¬ç‰¹å¾å¼•å¯¼è§†è§‰ç‰¹å¾
   - å¤šå±‚çº§èåˆï¼šä¸åŒå±‚çº§ä½¿ç”¨å¯¹åº”çš„æ–‡æœ¬ç‰¹å¾

5. **Transformerè§£ç å™¨**
   - å±‚æ•°ï¼š6å±‚
   - æŸ¥è¯¢æ•°ï¼š300ä¸ª
   - æ–‡æœ¬å¼•å¯¼ï¼šæ¯å±‚éƒ½ä½¿ç”¨æ–‡æœ¬ç‰¹å¾
   - è¾“å‡ºï¼šä¸­é—´å±‚ç»“æœï¼ˆç”¨äºæ·±ç›‘ç£ï¼‰

6. **æ£€æµ‹å¤´**
   - åˆ†ç±»å¤´ï¼šå¯¹æ¯”å­¦ä¹ ï¼ˆæŸ¥è¯¢ç‰¹å¾ vs æ–‡æœ¬ç‰¹å¾ï¼‰
   - å›å½’å¤´ï¼šMLPï¼ˆé¢„æµ‹è¾¹ç•Œæ¡†ï¼‰
   - å¤šå°ºåº¦ï¼šæ¯å±‚ç‹¬ç«‹çš„å›å½’å¤´

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚

```bash
Python >= 3.8
PyTorch >= 1.10
CUDA >= 11.0 (æ¨è)
```

### å®‰è£…ä¾èµ–

```bash
cd /home/ubuntu22/Projects/RemoteCLIP-main/experiment3
pip install -r requirements.txt
```

### æ•°æ®å‡†å¤‡

ç¡®ä¿DIORæ•°æ®é›†å·²ç»æ•´ç†å¥½ï¼š

```
datasets/DIOR/
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ trainval/
â”‚   â””â”€â”€ test/
â”œâ”€â”€ annotations/
â”‚   â””â”€â”€ horizontal/
â””â”€â”€ splits/
    â”œâ”€â”€ train.txt
    â”œâ”€â”€ val.txt
    â””â”€â”€ test.txt
```

### è®­ç»ƒ

```bash
# åŸºç¡€è®­ç»ƒ
python train.py \
  --data_dir ../datasets/DIOR \
  --output_dir ./outputs \
  --batch_size 8 \
  --epochs 50

# è‡ªå®šä¹‰é…ç½®
python train.py \
  --data_dir ../datasets/DIOR \
  --output_dir ./outputs \
  --batch_size 4 \
  --epochs 100 \
  --lr 1e-4 \
  --num_workers 8
```

### æ¨ç†

```bash
# å•å¼ å›¾åƒæ¨ç†
python inference/inference_engine.py \
  --checkpoint outputs/checkpoints/best.pth \
  --image ../datasets/DIOR/images/trainval/00001.jpg \
  --output result.jpg \
  --score_threshold 0.5

# æ‰¹é‡æ¨ç†
python inference/batch_inference.py \
  --checkpoint outputs/checkpoints/best.pth \
  --image_dir ../datasets/DIOR/images/test \
  --output_dir outputs/results
```

### è¯„ä¼°

```bash
python evaluate.py \
  --checkpoint outputs/checkpoints/best.pth \
  --data_dir ../datasets/DIOR \
  --output evaluation_results.json \
  --iou_threshold 0.5
```

## âš™ï¸ é…ç½®è¯´æ˜

ä¸»è¦é…ç½®åœ¨ `config/default_config.py`ï¼š

```python
# æ¨¡å‹é…ç½®
num_queries: int = 300              # æŸ¥è¯¢æ•°é‡
num_decoder_layers: int = 6         # è§£ç å™¨å±‚æ•°
d_model: int = 256                  # æ¨¡å‹ç»´åº¦

# RemoteCLIPé…ç½®
remoteclip_model: str = 'RN50'      # RN50/ViT-B-32/ViT-L-14
freeze_remoteclip: bool = True      # æ˜¯å¦å†»ç»“

# æŸå¤±æƒé‡
loss_cls_weight: float = 1.0        # åˆ†ç±»æŸå¤±
loss_bbox_weight: float = 5.0       # L1æŸå¤±
loss_giou_weight: float = 2.0       # GIoUæŸå¤±

# è®­ç»ƒé…ç½®
batch_size: int = 8
num_epochs: int = 50
learning_rate: float = 1e-4
```

## ğŸ“Š æ•°æ®é›†æ”¯æŒ

### DIORæ•°æ®é›†

- **å›¾åƒæ•°é‡**ï¼š23,463å¼ 
- **ç±»åˆ«æ•°é‡**ï¼š20ç±»
- **æ ‡æ³¨æ ¼å¼**ï¼šVOC XMLï¼ˆæ°´å¹³æ¡†ï¼‰
- **å›¾åƒå°ºå¯¸**ï¼š800Ã—800ï¼ˆç»Ÿä¸€è°ƒæ•´ï¼‰

### æ”¯æŒçš„ç±»åˆ«

```python
DIOR_CLASSES = [
    'airplane', 'airport', 'baseballfield', 'basketballcourt', 'bridge',
    'chimney', 'dam', 'Expressway-Service-area', 'Expressway-toll-station',
    'golffield', 'groundtrackfield', 'harbor', 'overpass', 'ship',
    'stadium', 'storagetank', 'tenniscourt', 'trainstation', 'vehicle', 'windmill'
]
```

## ğŸ”¬ æŠ€æœ¯ç»†èŠ‚

### æŸå¤±å‡½æ•°

1. **å˜ç„¦æŸå¤±ï¼ˆVarifocal Lossï¼‰**
   - å…¬å¼ï¼š`VFL(p,q) = -q(q-p)^Î³ log(p)`
   - ç”¨é€”ï¼šåˆ†ç±»
   - ä¼˜åŠ¿ï¼šIoUåŠ æƒï¼Œå…³æ³¨é«˜è´¨é‡æ ·æœ¬

2. **L1æŸå¤±**
   - ç”¨é€”ï¼šè¾¹ç•Œæ¡†å›å½’
   - å½’ä¸€åŒ–åæ ‡ï¼š[0, 1]

3. **GIoUæŸå¤±**
   - å…¬å¼ï¼š`L_GIoU = 1 - GIoU`
   - ç”¨é€”ï¼šè¾¹ç•Œæ¡†å›å½’
   - ä¼˜åŠ¿ï¼šè€ƒè™‘æ¡†çš„å½¢çŠ¶å’Œä½ç½®

### åŒ¹é…ç­–ç•¥

ä½¿ç”¨**åŒˆç‰™åˆ©ç®—æ³•**è¿›è¡ŒäºŒåˆ†å›¾åŒ¹é…ï¼š

```
ä»£ä»· = Î±Â·åˆ†ç±»ä»£ä»· + Î²Â·L1ä»£ä»· + Î³Â·GIoUä»£ä»·
```

### è®­ç»ƒç­–ç•¥

1. **æƒé‡å†»ç»“**ï¼šRemoteCLIPéª¨å¹²ç½‘ç»œä¿æŒå†»ç»“
2. **å­¦ä¹ ç‡**ï¼šæ£€æµ‹æ¨¡å— 1e-4ï¼Œéª¨å¹²ç½‘ç»œ 1e-5ï¼ˆå¯é€‰ï¼‰
3. **æ•°æ®å¢å¼º**ï¼šéšæœºç¿»è½¬ã€é¢œè‰²æŠ–åŠ¨ã€å°ºå¯¸è°ƒæ•´
4. **ä¼˜åŒ–å™¨**ï¼šAdamW (weight_decay=1e-4)
5. **å­¦ä¹ ç‡è°ƒåº¦**ï¼šStepLR (step_size=20, gamma=0.1)

## ğŸ“ˆ æ€§èƒ½æŒ‡æ ‡

### è¯„ä¼°æŒ‡æ ‡

- **mAP@0.5**ï¼šIoUé˜ˆå€¼ä¸º0.5çš„å¹³å‡ç²¾åº¦
- **AP per class**ï¼šæ¯ä¸ªç±»åˆ«çš„å¹³å‡ç²¾åº¦
- **Precision / Recall**ï¼šç²¾ç¡®ç‡å’Œå¬å›ç‡

### é¢„æœŸæ€§èƒ½

| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| mAP@0.5 | å¾…æµ‹è¯• |
| æ¨ç†é€Ÿåº¦ | ~10 FPS (RTX 3090) |
| å†…å­˜å ç”¨ | ~8GB |

## ğŸ› ï¸ å¼€å‘æŒ‡å—

### æµ‹è¯•å•ä¸ªæ¨¡å—

```bash
# æµ‹è¯•FPN
python encoder/fpn.py

# æµ‹è¯•è§£ç å™¨
python decoder/transformer_decoder.py

# æµ‹è¯•æŸå¤±å‡½æ•°
python losses/varifocal_loss.py

# æµ‹è¯•æ•°æ®åŠ è½½å™¨
python utils/data_loader.py
```

### è‡ªå®šä¹‰å¼€å‘

1. **æ·»åŠ æ–°çš„ç‰¹å¾æå–å™¨**
   - ä¿®æ”¹ `backbone/remoteclip_backbone.py`
   - è°ƒæ•´ `output_layers` å‚æ•°

2. **ä¿®æ”¹æ£€æµ‹å¤´**
   - ç¼–è¾‘ `head/classification_head.py`
   - ç¼–è¾‘ `head/regression_head.py`

3. **è°ƒæ•´æŸå¤±å‡½æ•°**
   - ä¿®æ”¹ `models/criterion.py`
   - è°ƒæ•´æƒé‡å‚æ•°

## ğŸ“ ä½¿ç”¨ç¤ºä¾‹

### Python API

```python
from models.ova_detr import OVADETR
from config.default_config import DefaultConfig
from inference.inference_engine import InferenceEngine

# æ–¹å¼1ï¼šç›´æ¥ä½¿ç”¨æ¨¡å‹
config = DefaultConfig()
model = OVADETR(config)

# æ–¹å¼2ï¼šä½¿ç”¨æ¨ç†å¼•æ“
engine = InferenceEngine(
    checkpoint_path='outputs/checkpoints/best.pth',
    score_threshold=0.5
)

result = engine.predict_single('test.jpg')
vis_image = engine.visualize('test.jpg', result)
vis_image.save('result.jpg')
```

## ğŸ› å¸¸è§é—®é¢˜

### Q1: CUDAå†…å­˜ä¸è¶³

A: å‡å°batch_sizeæˆ–å›¾åƒå°ºå¯¸ï¼š

```python
config.batch_size = 4
config.image_size = (600, 600)
```

### Q2: è®­ç»ƒé€Ÿåº¦æ…¢

A: å¢åŠ num_workersæˆ–ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼š

```bash
python train.py --num_workers 8 --amp
```

### Q3: mAPå¾ˆä½

A: æ£€æŸ¥ä»¥ä¸‹å‡ ç‚¹ï¼š
1. æ•°æ®é›†æ˜¯å¦æ­£ç¡®åŠ è½½
2. æ–‡æœ¬ç‰¹å¾æ˜¯å¦æ­£ç¡®æå–
3. æŸå¤±æƒé‡æ˜¯å¦åˆç†
4. å­¦ä¹ ç‡æ˜¯å¦è¿‡å¤§æˆ–è¿‡å°

## ğŸ”— å‚è€ƒèµ„æº

### ç›¸å…³è®ºæ–‡

1. **OVA-DETR**: Open-Vocabulary DETR with Conditional Matching
2. **DETR**: End-to-End Object Detection with Transformers
3. **RemoteCLIP**: A Vision Language Foundation Model for Remote Sensing

### ä»£ç å‚è€ƒ

- [DETR Official](https://github.com/facebookresearch/detr)
- [RemoteCLIP](https://github.com/ChenDelong1999/RemoteCLIP)

## ğŸ“§ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æäº¤Issueæˆ–è”ç³»å¼€å‘è€…ã€‚

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®éµå¾ªMITè®¸å¯è¯ã€‚

---

**åˆ›å»ºæ—¥æœŸ**ï¼š2025-10-24  
**æœ€åæ›´æ–°**ï¼š2025-10-24  
**ç‰ˆæœ¬**ï¼šv1.0
