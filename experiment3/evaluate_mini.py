#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Experiment3 åœ¨ mini_dataset ä¸Šçš„ç®€åŒ–è¯„ä¼°

ç”±äºæ²¡æœ‰è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œè¿™é‡Œæµ‹è¯•æ¨¡å‹æ¶æ„å’Œæ¨ç†æµç¨‹
"""

import torch
import time
import sys
from pathlib import Path
import json

sys.path.append('..')

from config.default_config import DefaultConfig
from models.ova_detr import OVADETR
from utils.data_loader import DIOR_CLASSES, DiorDataset, collate_fn
from utils.transforms import get_transforms
from torch.utils.data import DataLoader


def evaluate_architecture():
    """è¯„ä¼°æ¨¡å‹æ¶æ„"""
    
    print("=" * 70)
    print("Experiment3: OVA-DETR æ¶æ„è¯„ä¼°")
    print("=" * 70)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"\nè®¾å¤‡: {device}")
    
    # é…ç½®
    config = DefaultConfig()
    config.batch_size = 2
    
    print("\nğŸ“‹ æ¨¡å‹é…ç½®:")
    print(f"  RemoteCLIP: {config.remoteclip_model}")
    print(f"  æŸ¥è¯¢æ•°é‡: {config.num_queries}")
    print(f"  è§£ç å™¨å±‚æ•°: {config.num_decoder_layers}")
    print(f"  æ¨¡å‹ç»´åº¦: {config.d_model}")
    print(f"  å†»ç»“backbone: {config.freeze_remoteclip}")
    
    # åˆ›å»ºæ¨¡å‹
    print("\nåˆ›å»ºæ¨¡å‹...")
    model = OVADETR(config).to(device)
    model.eval()
    
    # ç»Ÿè®¡å‚æ•°
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    frozen_params = total_params - trainable_params
    
    print(f"\nğŸ“Š æ¨¡å‹å‚æ•°:")
    print(f"  æ€»å‚æ•°: {total_params:,} ({total_params/1e6:.2f}M)")
    print(f"  å¯è®­ç»ƒ: {trainable_params:,} ({trainable_params/1e6:.2f}M)")
    print(f"  å†»ç»“: {frozen_params:,} ({frozen_params/1e6:.2f}M)")
    
    # æå–æ–‡æœ¬ç‰¹å¾
    print("\næå–æ–‡æœ¬ç‰¹å¾...")
    with torch.no_grad():
        text_features = model.backbone.forward_text(DIOR_CLASSES).to(device)
    print(f"  æ–‡æœ¬ç‰¹å¾: {text_features.shape}")
    print(f"  ç±»åˆ«æ•°: {len(DIOR_CLASSES)}")
    
    # åŠ è½½æ•°æ®
    print("\nåŠ è½½ mini_dataset...")
    transforms = get_transforms(mode='val', image_size=config.image_size)
    
    dataset = DiorDataset(
        root_dir='datasets/mini_dataset',
        split='train',
        transforms=transforms
    )
    
    data_loader = DataLoader(
        dataset,
        batch_size=config.batch_size,
        shuffle=False,
        collate_fn=collate_fn,
        num_workers=0
    )
    
    print(f"  æ•°æ®é›†å¤§å°: {len(dataset)}")
    print(f"  æ‰¹æ¬¡æ•°: {len(data_loader)}")
    
    # æµ‹è¯•æ¨ç†
    print("\nğŸ”¬ æµ‹è¯•æ¨ç†æµç¨‹...")
    
    total_time = 0
    num_images = 0
    num_detections = 0
    
    start_time = time.time()
    
    with torch.no_grad():
        for batch_idx, (images, targets) in enumerate(data_loader):
            batch_start = time.time()
            
            images = images.to(device)
            
            # å‰å‘ä¼ æ’­
            outputs = model(images, text_features)
            
            # ç»Ÿè®¡
            pred_logits = outputs['pred_logits'][-1]
            scores = pred_logits.sigmoid().max(dim=-1)[0]
            
            for i in range(scores.shape[0]):
                detections = (scores[i] > 0.3).sum().item()
                num_detections += detections
                num_images += 1
            
            batch_time = time.time() - batch_start
            total_time += batch_time
            
            if batch_idx == 0:
                print(f"\n  æ‰¹æ¬¡ 0:")
                print(f"    å›¾åƒshape: {images.shape}")
                print(f"    pred_logits: {outputs['pred_logits'].shape}")
                print(f"    pred_boxes: {outputs['pred_boxes'].shape}")
                print(f"    æ‰¹æ¬¡ç”¨æ—¶: {batch_time:.3f}ç§’")
            
            if batch_idx >= 5:  # åªæµ‹è¯•å‰å‡ ä¸ªæ‰¹æ¬¡
                break
    
    inference_time = time.time() - start_time
    
    # GPUå†…å­˜
    if torch.cuda.is_available():
        gpu_memory = {
            'allocated_MB': torch.cuda.memory_allocated() / 1024**2,
            'reserved_MB': torch.cuda.memory_reserved() / 1024**2,
            'max_allocated_MB': torch.cuda.max_memory_allocated() / 1024**2
        }
    else:
        gpu_memory = {}
    
    # ç»“æœ
    print("\n" + "=" * 70)
    print("æ¨ç†æ€§èƒ½æµ‹è¯•")
    print("=" * 70)
    print(f"  æµ‹è¯•å›¾ç‰‡æ•°: {num_images}")
    print(f"  æ€»ç”¨æ—¶: {inference_time:.2f}ç§’")
    print(f"  FPS: {num_images/inference_time:.2f}")
    print(f"  å¹³å‡æ£€æµ‹æ•°/å›¾: {num_detections/num_images:.1f}")
    
    if gpu_memory:
        print(f"\nğŸ’¾ GPUå†…å­˜:")
        print(f"  å·²åˆ†é…: {gpu_memory['allocated_MB']:.1f} MB")
        print(f"  å·²ä¿ç•™: {gpu_memory['reserved_MB']:.1f} MB")
        print(f"  å³°å€¼: {gpu_memory['max_allocated_MB']:.1f} MB")
    
    # ä¿å­˜ç»“æœ
    results = {
        'experiment': 'Experiment3',
        'model': 'OVA-DETR with RemoteCLIP',
        'architecture': {
            'backbone': config.remoteclip_model,
            'num_queries': config.num_queries,
            'num_decoder_layers': config.num_decoder_layers,
            'd_model': config.d_model,
            'freeze_backbone': config.freeze_remoteclip
        },
        'parameters': {
            'total': total_params,
            'trainable': trainable_params,
            'frozen': frozen_params,
            'total_M': total_params / 1e6,
            'trainable_M': trainable_params / 1e6
        },
        'performance': {
            'num_images_tested': num_images,
            'inference_time': inference_time,
            'fps': num_images / inference_time,
            'avg_detections_per_image': num_detections / num_images
        },
        'gpu_memory': gpu_memory,
        'note': 'æœªè®­ç»ƒæ¨¡å‹ï¼Œä»…æµ‹è¯•æ¶æ„å’Œæ¨ç†é€Ÿåº¦'
    }
    
    output_file = Path('experiment3/results_mini_dataset.json')
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    print(f"\nâœ… ç»“æœä¿å­˜åˆ°: {output_file}")
    
    return results


if __name__ == '__main__':
    results = evaluate_architecture()
    
    print("\n" + "=" * 70)
    print("Experiment3 æ¶æ„è¯„ä¼°å®Œæˆï¼")
    print("=" * 70)


