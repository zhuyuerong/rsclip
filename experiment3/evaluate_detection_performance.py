#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Experiment3 æ£€æµ‹æ€§èƒ½è¯„ä¼°
è®¡ç®—mAP@50, mAP@75, mAP@[.5:.95]
"""

import torch
import numpy as np
import sys
from pathlib import Path
from PIL import Image
import json

sys.path.append('..')

from config.default_config import DefaultConfig
from models.ova_detr import OVADETR
from utils.data_loader import DIOR_CLASSES
from datasets.mini_dataset.mini_dataset_loader import MiniDataset
import torchvision.transforms as T


def calculate_iou(box1, box2):
    """è®¡ç®—ä¸¤ä¸ªæ¡†çš„IoU (boxesæ ¼å¼: [x1, y1, x2, y2])"""
    x1 = max(box1[0], box2[0])
    y1 = max(box1[1], box2[1])
    x2 = min(box1[2], box2[2])
    y2 = min(box1[3], box2[3])
    
    intersection = max(0, x2 - x1) * max(0, y2 - y1)
    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])
    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])
    union = area1 + area2 - intersection
    
    return intersection / union if union > 0 else 0


def calculate_ap_per_class(predictions, ground_truths, class_id, iou_threshold=0.5):
    """è®¡ç®—å•ä¸ªç±»åˆ«çš„AP"""
    class_preds = [p for p in predictions if p['category_id'] == class_id]
    class_gts = [gt for gt in ground_truths if gt['category_id'] == class_id]
    
    if len(class_gts) == 0:
        return None
    
    if len(class_preds) == 0:
        return 0.0
    
    # æŒ‰ç½®ä¿¡åº¦æ’åº
    class_preds = sorted(class_preds, key=lambda x: x['score'], reverse=True)
    
    # æ ‡è®°GTæ˜¯å¦è¢«åŒ¹é…
    gt_matched = [False] * len(class_gts)
    
    tp = []
    fp = []
    
    for pred in class_preds:
        max_iou = 0
        max_gt_idx = -1
        
        # æ‰¾åˆ°åŒä¸€å›¾åƒçš„GT
        for gt_idx, gt in enumerate(class_gts):
            if gt['image_id'] == pred['image_id']:
                iou = calculate_iou(pred['bbox'], gt['bbox'])
                if iou > max_iou:
                    max_iou = iou
                    max_gt_idx = gt_idx
        
        if max_iou >= iou_threshold and not gt_matched[max_gt_idx]:
            tp.append(1)
            fp.append(0)
            gt_matched[max_gt_idx] = True
        else:
            tp.append(0)
            fp.append(1)
    
    tp_cumsum = np.cumsum(tp)
    fp_cumsum = np.cumsum(fp)
    
    recalls = tp_cumsum / len(class_gts)
    precisions = tp_cumsum / (tp_cumsum + fp_cumsum + 1e-10)
    
    # è®¡ç®—AP (11ç‚¹æ’å€¼)
    ap = 0.0
    for t in np.arange(0, 1.1, 0.1):
        if np.sum(recalls >= t) == 0:
            p = 0
        else:
            p = np.max(precisions[recalls >= t])
        ap += p / 11.0
    
    return ap


def evaluate():
    """è¯„ä¼°æ£€æµ‹æ€§èƒ½"""
    
    print("=" * 70)
    print("Experiment3: OVA-DETR æ£€æµ‹æ€§èƒ½è¯„ä¼°")
    print("=" * 70)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"\nè®¾å¤‡: {device}")
    
    # é…ç½®
    config = DefaultConfig()
    
    print("\nåˆ›å»ºæ¨¡å‹...")
    model = OVADETR(config).to(device)
    model.eval()
    
    print("å‡†å¤‡æ–‡æœ¬ç‰¹å¾...")
    with torch.no_grad():
        text_features = model.backbone.forward_text(DIOR_CLASSES).to(device)
    
    print(f"æ–‡æœ¬ç‰¹å¾: {text_features.shape}")
    
    print("\nåŠ è½½mini_dataset...")
    
    # ä¸ä½¿ç”¨transformsï¼Œæ‰‹åŠ¨å¤„ç†
    dataset = MiniDataset(
        root_dir='../datasets/mini_dataset',
        split='test',
        transforms=None
    )
    
    # å®šä¹‰å›¾åƒè½¬æ¢
    img_transform = T.Compose([
        T.Resize((224, 224)),
        T.ToTensor(),
        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    print(f"æµ‹è¯•é›†å¤§å°: {len(dataset)} å¼ å›¾")
    
    if len(dataset) == 0:
        print("âŒ æµ‹è¯•é›†ä¸ºç©ºï¼Œæ— æ³•è¯„ä¼°ï¼")
        return
    
    predictions = []
    ground_truths = []
    
    print("\nå¼€å§‹æ¨ç†...")
    with torch.no_grad():
        for idx in range(len(dataset)):
            if idx % 5 == 0:
                print(f"  å¤„ç†: {idx+1}/{len(dataset)}")
            
            # åŠ è½½æ•°æ®
            image_pil, target = dataset[idx]
            
            # è½¬æ¢å›¾åƒ
            image = img_transform(image_pil).unsqueeze(0).to(device)  # [1, 3, H, W]
            
            # æ¨¡å‹æ¨ç†
            outputs = model(image, text_features)
            
            # è§£æè¾“å‡º
            pred_boxes = outputs['pred_boxes'][0]  # [num_queries, 4] cxcywh normalized
            pred_logits = outputs['pred_logits'][0]  # [num_queries, num_classes]
            
            # è®¡ç®—ç½®ä¿¡åº¦
            pred_scores = pred_logits.softmax(-1)
            max_scores, pred_labels = pred_scores.max(-1)
            
            # è¿‡æ»¤ä½ç½®ä¿¡åº¦
            keep = max_scores > config.score_threshold
            pred_boxes = pred_boxes[keep]
            pred_labels = pred_labels[keep]
            max_scores = max_scores[keep]
            
            # è½¬æ¢boxæ ¼å¼ (cxcywh normalized -> xyxy pixel)
            H, W = image.shape[2], image.shape[3]  # [1, 3, H, W]
            boxes_xyxy = torch.zeros_like(pred_boxes)
            boxes_xyxy[:, 0] = (pred_boxes[:, 0] - pred_boxes[:, 2] / 2) * W
            boxes_xyxy[:, 1] = (pred_boxes[:, 1] - pred_boxes[:, 3] / 2) * H
            boxes_xyxy[:, 2] = (pred_boxes[:, 0] + pred_boxes[:, 2] / 2) * W
            boxes_xyxy[:, 3] = (pred_boxes[:, 1] + pred_boxes[:, 3] / 2) * H
            
            # æ”¶é›†é¢„æµ‹
            for box, label, score in zip(boxes_xyxy, pred_labels, max_scores):
                predictions.append({
                    'image_id': idx,
                    'category_id': int(label),
                    'bbox': box.cpu().tolist(),
                    'score': float(score)
                })
            
            # æ”¶é›†GT
            for box, label in zip(target['boxes'], target['labels']):
                ground_truths.append({
                    'image_id': idx,
                    'category_id': int(label),
                    'bbox': box.tolist()
                })
    
    print(f"\næ”¶é›†å®Œæˆ:")
    print(f"  é¢„æµ‹æ¡†æ•°é‡: {len(predictions)}")
    print(f"  GTæ¡†æ•°é‡: {len(ground_truths)}")
    
    # è®¡ç®—æ‰€æœ‰ç±»åˆ«çš„mAP
    print("\nè®¡ç®—æ£€æµ‹æŒ‡æ ‡...")
    
    all_classes = set([p['category_id'] for p in predictions] + [gt['category_id'] for gt in ground_truths])
    
    # mAP@50
    aps_50 = {}
    for class_id in all_classes:
        ap = calculate_ap_per_class(predictions, ground_truths, class_id, iou_threshold=0.5)
        if ap is not None:
            aps_50[class_id] = ap
    
    mAP_50 = np.mean(list(aps_50.values())) if aps_50 else 0.0
    
    # mAP@75
    aps_75 = {}
    for class_id in all_classes:
        ap = calculate_ap_per_class(predictions, ground_truths, class_id, iou_threshold=0.75)
        if ap is not None:
            aps_75[class_id] = ap
    
    mAP_75 = np.mean(list(aps_75.values())) if aps_75 else 0.0
    
    # mAP@[.5:.95] (COCOé£æ ¼)
    mAPs_coco = []
    for iou_thr in np.arange(0.5, 1.0, 0.05):
        aps = {}
        for class_id in all_classes:
            ap = calculate_ap_per_class(predictions, ground_truths, class_id, iou_threshold=iou_thr)
            if ap is not None:
                aps[class_id] = ap
        if aps:
            mAPs_coco.append(np.mean(list(aps.values())))
    
    mAP_coco = np.mean(mAPs_coco) if mAPs_coco else 0.0
    
    # æ‰“å°ç»“æœ
    print("\n" + "=" * 70)
    print("æ£€æµ‹æ€§èƒ½æŒ‡æ ‡")
    print("=" * 70)
    
    print(f"\nğŸ“Š æ€»ä½“æŒ‡æ ‡:")
    print(f"  mAP@50:       {mAP_50:.4f}")
    print(f"  mAP@75:       {mAP_75:.4f}")
    print(f"  mAP@[.5:.95]: {mAP_coco:.4f}")
    print(f"  æ£€æµ‹ç±»åˆ«æ•°:   {len(aps_50)}/{len(DIOR_CLASSES)}")
    
    print(f"\nğŸ“‹ å„ç±»åˆ«AP@50:")
    for class_id in sorted(aps_50.keys()):
        if class_id < len(DIOR_CLASSES):
            class_name = DIOR_CLASSES[class_id]
            ap = aps_50[class_id]
            print(f"  {class_name:20s}: {ap:.4f}")
    
    # ä¿å­˜ç»“æœ
    results = {
        'dataset': 'mini_dataset',
        'split': 'test',
        'num_images': len(dataset),
        'num_predictions': len(predictions),
        'num_ground_truths': len(ground_truths),
        'metrics': {
            'mAP@50': float(mAP_50),
            'mAP@75': float(mAP_75),
            'mAP@[.5:.95]': float(mAP_coco),
            'num_classes_detected': len(aps_50)
        },
        'AP_per_class_@50': {
            DIOR_CLASSES[k]: float(v) 
            for k, v in aps_50.items() 
            if k < len(DIOR_CLASSES)
        }
    }
    
    with open('detection_results.json', 'w') as f:
        json.dump(results, f, indent=2)
    
    print(f"\nâœ… ç»“æœä¿å­˜åˆ°: detection_results.json")
    print("\n" + "=" * 70)
    
    return results


if __name__ == '__main__':
    evaluate()

