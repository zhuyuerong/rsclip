#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OVA-DETR æ¼”ç¤ºè„šæœ¬

å±•ç¤ºå¦‚ä½•ä½¿ç”¨æ•´ä¸ªç³»ç»Ÿè¿›è¡Œè®­ç»ƒã€æ¨ç†å’Œè¯„ä¼°
"""

import torch
import argparse
from pathlib import Path

from config.default_config import DefaultConfig
from models.ova_detr import OVADETR
from utils.data_loader import DIOR_CLASSES


def demo_model_creation():
    """æ¼”ç¤ºï¼šåˆ›å»ºæ¨¡å‹"""
    
    print("=" * 70)
    print("æ¼”ç¤º1: åˆ›å»ºOVA-DETRæ¨¡å‹")
    print("=" * 70)
    
    # é…ç½®
    config = DefaultConfig()
    
    # åˆ›å»ºæ¨¡å‹
    model = OVADETR(config)
    
    # ç»Ÿè®¡å‚æ•°
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    print(f"\næ¨¡å‹ä¿¡æ¯:")
    print(f"  æ€»å‚æ•°: {total_params:,}")
    print(f"  å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
    print(f"  å†»ç»“å‚æ•°: {total_params - trainable_params:,}")
    
    print(f"\né…ç½®:")
    print(f"  æŸ¥è¯¢æ•°é‡: {config.num_queries}")
    print(f"  è§£ç å™¨å±‚æ•°: {config.num_decoder_layers}")
    print(f"  æ¨¡å‹ç»´åº¦: {config.d_model}")
    
    return model, config


def demo_forward_pass(model, config):
    """æ¼”ç¤ºï¼šå‰å‘ä¼ æ’­"""
    
    print("\n" + "=" * 70)
    print("æ¼”ç¤º2: å‰å‘ä¼ æ’­")
    print("=" * 70)
    
    # å‡†å¤‡è¾“å…¥
    batch_size = 2
    images = torch.randn(batch_size, 3, 800, 800)
    
    # æå–æ–‡æœ¬ç‰¹å¾
    with torch.no_grad():
        text_features = model.backbone.forward_text(DIOR_CLASSES)
    
    print(f"\nè¾“å…¥:")
    print(f"  å›¾åƒ: {images.shape}")
    print(f"  æ–‡æœ¬ç‰¹å¾: {text_features.shape}")
    print(f"  ç±»åˆ«æ•°: {len(DIOR_CLASSES)}")
    
    # å‰å‘ä¼ æ’­
    model.eval()
    with torch.no_grad():
        outputs = model(images, text_features)
    
    print(f"\nè¾“å‡º:")
    print(f"  åˆ†ç±»logits: {outputs['pred_logits'].shape}")
    print(f"  è¾¹ç•Œæ¡†: {outputs['pred_boxes'].shape}")
    print(f"  å¢å¼ºæ–‡æœ¬: {outputs['text_features'].shape}")
    
    # è§£é‡Šè¾“å‡ºå½¢çŠ¶
    num_layers, B, num_queries, num_classes = outputs['pred_logits'].shape
    print(f"\nè¾“å‡ºè§£é‡Š:")
    print(f"  è§£ç å™¨å±‚æ•°: {num_layers}")
    print(f"  æ‰¹æ¬¡å¤§å°: {B}")
    print(f"  æŸ¥è¯¢æ•°é‡: {num_queries}")
    print(f"  ç±»åˆ«æ•°: {num_classes}")


def demo_inference():
    """æ¼”ç¤ºï¼šæ¨ç†æµç¨‹"""
    
    print("\n" + "=" * 70)
    print("æ¼”ç¤º3: æ¨ç†æµç¨‹")
    print("=" * 70)
    
    print("\næ¨ç†æ­¥éª¤:")
    print("1. åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹")
    print("   engine = InferenceEngine(checkpoint_path='best.pth')")
    
    print("\n2. å¯¹å•å¼ å›¾åƒæ¨ç†")
    print("   result = engine.predict_single('test.jpg')")
    
    print("\n3. å¯è§†åŒ–ç»“æœ")
    print("   vis_image = engine.visualize('test.jpg', result)")
    print("   vis_image.save('result.jpg')")
    
    print("\nç»“æœæ ¼å¼:")
    print("  {")
    print("    'boxes': (N, 4),      # è¾¹ç•Œæ¡† [x1, y1, x2, y2]")
    print("    'scores': (N,),       # ç½®ä¿¡åº¦åˆ†æ•°")
    print("    'labels': (N,),       # ç±»åˆ«ç´¢å¼•")
    print("    'class_names': [...]  # ç±»åˆ«åç§°")
    print("  }")


def demo_training_workflow():
    """æ¼”ç¤ºï¼šè®­ç»ƒæµç¨‹"""
    
    print("\n" + "=" * 70)
    print("æ¼”ç¤º4: è®­ç»ƒæµç¨‹")
    print("=" * 70)
    
    print("\nå®Œæ•´è®­ç»ƒå‘½ä»¤:")
    print("-" * 70)
    print("""
python train.py \\
  --data_dir ../datasets/DIOR \\
  --output_dir ./outputs \\
  --batch_size 8 \\
  --epochs 50 \\
  --lr 1e-4 \\
  --num_workers 8
    """)
    
    print("\nè®­ç»ƒæµç¨‹:")
    print("1. åŠ è½½DIORæ•°æ®é›†")
    print("2. åˆ›å»ºOVA-DETRæ¨¡å‹")
    print("3. æå–æ–‡æœ¬ç‰¹å¾ï¼ˆDIOR 20ä¸ªç±»åˆ«ï¼‰")
    print("4. è®¾ç½®ä¼˜åŒ–å™¨ï¼ˆAdamWï¼‰")
    print("5. å¾ªç¯è®­ç»ƒï¼š")
    print("   - å‰å‘ä¼ æ’­")
    print("   - åŒˆç‰™åˆ©åŒ¹é…")
    print("   - è®¡ç®—æŸå¤±ï¼ˆå˜ç„¦ + L1 + GIoUï¼‰")
    print("   - åå‘ä¼ æ’­")
    print("   - æ›´æ–°å‚æ•°")
    print("6. ä¿å­˜æ£€æŸ¥ç‚¹")
    
    print("\nè¾“å‡º:")
    print("  outputs/")
    print("  â”œâ”€â”€ checkpoints/")
    print("  â”‚   â”œâ”€â”€ best.pth")
    print("  â”‚   â”œâ”€â”€ latest.pth")
    print("  â”‚   â””â”€â”€ epoch_*.pth")
    print("  â””â”€â”€ logs/")
    print("      â””â”€â”€ tensorboardæ—¥å¿—")


def demo_evaluation():
    """æ¼”ç¤ºï¼šè¯„ä¼°æµç¨‹"""
    
    print("\n" + "=" * 70)
    print("æ¼”ç¤º5: è¯„ä¼°æµç¨‹")
    print("=" * 70)
    
    print("\nè¯„ä¼°å‘½ä»¤:")
    print("-" * 70)
    print("""
python evaluate.py \\
  --checkpoint outputs/checkpoints/best.pth \\
  --data_dir ../datasets/DIOR \\
  --output evaluation_results.json \\
  --iou_threshold 0.5
    """)
    
    print("\nè¯„ä¼°æŒ‡æ ‡:")
    print("1. mAP@0.5 - IoUé˜ˆå€¼ä¸º0.5çš„å¹³å‡ç²¾åº¦")
    print("2. AP per class - æ¯ä¸ªç±»åˆ«çš„å¹³å‡ç²¾åº¦")
    print("3. Precision / Recall - ç²¾ç¡®ç‡å’Œå¬å›ç‡")
    
    print("\nè¯„ä¼°ç»“æœç¤ºä¾‹:")
    print("-" * 70)
    print("""
mAP@0.5: 0.6542
è¯„ä¼°ç±»åˆ«æ•°: 20/20

å„ç±»åˆ«AP:
  airplane                      : 0.7823
  ship                          : 0.7156
  harbor                        : 0.6891
  ...
    """)


def demo_dataset_info():
    """æ¼”ç¤ºï¼šæ•°æ®é›†ä¿¡æ¯"""
    
    print("\n" + "=" * 70)
    print("æ¼”ç¤º6: DIORæ•°æ®é›†")
    print("=" * 70)
    
    print("\næ•°æ®é›†ç»Ÿè®¡:")
    print(f"  ç±»åˆ«æ•°: {len(DIOR_CLASSES)}")
    print(f"  è®­ç»ƒé›†: ~8,000å¼ å›¾ç‰‡")
    print(f"  éªŒè¯é›†: ~2,000å¼ å›¾ç‰‡")
    print(f"  æµ‹è¯•é›†: ~11,738å¼ å›¾ç‰‡")
    
    print("\nç±»åˆ«åˆ—è¡¨:")
    for i, cls in enumerate(DIOR_CLASSES, 1):
        print(f"  {i:2d}. {cls}")
    
    print("\næ•°æ®æ ¼å¼:")
    print("  å›¾åƒ: JPG, 800Ã—800")
    print("  æ ‡æ³¨: VOC XML, æ°´å¹³è¾¹ç•Œæ¡†")
    print("  è¾¹ç•Œæ¡†: [xmin, ymin, xmax, ymax]")


def demo_architecture():
    """æ¼”ç¤ºï¼šæ¨¡å‹æ¶æ„"""
    
    print("\n" + "=" * 70)
    print("æ¼”ç¤º7: æ¨¡å‹æ¶æ„")
    print("=" * 70)
    
    print("""
å®Œæ•´æ¶æ„æµç¨‹:

è¾“å…¥å›¾åƒ (B, 3, 800, 800)
    â†“
[1] RemoteCLIPéª¨å¹²ç½‘ç»œ (å†»ç»“)
    â”œâ”€ å›¾åƒç¼–ç å™¨: æå–å¤šå±‚çº§ç‰¹å¾
    â”‚  â””â”€ layer2, layer3, layer4
    â””â”€ æ–‡æœ¬ç¼–ç å™¨: æå–æ–‡æœ¬ç‰¹å¾
       â””â”€ 20ä¸ªç±»åˆ«æ–‡æœ¬
    â†“
[2] FPNç‰¹å¾é‡‘å­—å¡”
    â”œâ”€ ä¾§å‘è¿æ¥ (1x1å·ç§¯)
    â”œâ”€ è‡ªé¡¶å‘ä¸‹èåˆ
    â””â”€ è¾“å‡º: 4å±‚256ç»´ç‰¹å¾
    â†“
[3] æ··åˆç¼–ç å™¨
    â”œâ”€ ä½ç½®ç¼–ç 
    â”œâ”€ Transformerç¼–ç  (6å±‚)
    â””â”€ å…¨å±€ç‰¹å¾å»ºæ¨¡
    â†“
[4] æ–‡æœ¬-è§†è§‰èåˆ
    â”œâ”€ è§†è§‰å¢å¼ºæ–‡æœ¬ (VAT)
    â”‚  â””â”€ äº¤å‰æ³¨æ„åŠ›: æ–‡æœ¬ â† è§†è§‰
    â””â”€ æ–‡æœ¬å¼•å¯¼è§†è§‰
       â””â”€ äº¤å‰æ³¨æ„åŠ›: è§†è§‰ â† æ–‡æœ¬
    â†“
[5] Transformerè§£ç å™¨ (6å±‚)
    â”œâ”€ ç›®æ ‡æŸ¥è¯¢: 300ä¸ªå¯å­¦ä¹ æŸ¥è¯¢
    â”œâ”€ è‡ªæ³¨æ„åŠ›: æŸ¥è¯¢ä¹‹é—´
    â”œâ”€ äº¤å‰æ³¨æ„åŠ›: æŸ¥è¯¢ â† è§†è§‰ç‰¹å¾
    â”œâ”€ äº¤å‰æ³¨æ„åŠ›: æŸ¥è¯¢ â† æ–‡æœ¬ç‰¹å¾
    â””â”€ FFN: ç‰¹å¾å˜æ¢
    â†“
[6] æ£€æµ‹å¤´
    â”œâ”€ åˆ†ç±»å¤´: å¯¹æ¯”å­¦ä¹ 
    â”‚  â””â”€ ç›¸ä¼¼åº¦: æŸ¥è¯¢ç‰¹å¾ Ã— æ–‡æœ¬ç‰¹å¾
    â””â”€ å›å½’å¤´: MLP
       â””â”€ è¾“å‡º: [cx, cy, w, h]
    â†“
è¾“å‡º:
  - åˆ†ç±»logits: (6, B, 300, 20)
  - è¾¹ç•Œæ¡†: (6, B, 300, 4)
    """)


def main():
    """ä¸»å‡½æ•°"""
    
    print("\n" + "ğŸ¯" * 35)
    print("OVA-DETR with RemoteCLIP - å®Œæ•´æ¼”ç¤º")
    print("ğŸ¯" * 35 + "\n")
    
    try:
        # æ¼”ç¤º1: åˆ›å»ºæ¨¡å‹
        model, config = demo_model_creation()
        
        # æ¼”ç¤º2: å‰å‘ä¼ æ’­
        demo_forward_pass(model, config)
        
        # æ¼”ç¤º3: æ¨ç†
        demo_inference()
        
        # æ¼”ç¤º4: è®­ç»ƒ
        demo_training_workflow()
        
        # æ¼”ç¤º5: è¯„ä¼°
        demo_evaluation()
        
        # æ¼”ç¤º6: æ•°æ®é›†
        demo_dataset_info()
        
        # æ¼”ç¤º7: æ¶æ„
        demo_architecture()
        
        print("\n" + "=" * 70)
        print("âœ… æ¼”ç¤ºå®Œæˆï¼")
        print("=" * 70)
        
        print("\nä¸‹ä¸€æ­¥:")
        print("1. è¿è¡Œå¿«é€Ÿå¯åŠ¨è„šæœ¬: bash quick_start.sh")
        print("2. å¼€å§‹è®­ç»ƒ: python train.py --help")
        print("3. æŸ¥çœ‹æ–‡æ¡£: cat README.md")
        
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main()

